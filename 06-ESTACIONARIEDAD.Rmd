# Estacionariedad

## El problema
Los fundamentos de las series de tiempo están basados en la
estacionalidad. Una serie de tiempo ${r_t}$ que estudia los retornos de
un activo a lo largo de tiempo es *estrictamente estacionaria* si la
distribución conjunta de los retornos $(r_{t1},\dots,r_{t1})$ es
*exactamente idéntica* en $(r_{t1+T},\dots,r_{t1+T})$, es decir cuando
pasa $T$ años, por ejemplo. En otras palabras, definiremos a una serie
de tiempo como un vector de variables ${X_t}$ aleatorias de dimensión
$T$, dado como: 

\begin{equation}
    X_1, X_2, X_3, \ldots ,X_T
\end{equation} 

Es decir, definiremos a una serie de tiempo como una
realización de un proceso estocástico --o un Proceso Generador de Datos
(PGD). Consideremos una muestra de los múltiples posibles resultados de
muestras de tamaño $T$, la colección dada por: 

\begin{equation}
    \{X^{(1)}_1, X^{(1)}_2, \ldots, X^{(1)}_T\}
    (\#eq:variast)
\end{equation}

Eventualmente podríamos estar dispuestos a observar este proceso
indefinidamente, de forma tal que estemos interesados en observar a la
secuencia dada por $\{ X^{(1)}_t \}^{\infty}_{t = 1}$, lo cual no
dejaría se ser sólo una de las tantas realizaciones o secuencias del
proceso estocástico original de la ecuación \@ref(eq:variast).

```{=tex}
\begin{eqnarray*}
    & \{X^{(2)}_1, X^{(2)}_2, \ldots, X^{(2)}_T\} & \\
    & \{X^{(3)}_1, X^{(3)}_2, \ldots, X^{(3)}_T\} & \\
    & \{X^{(4)}_1, X^{(4)}_2, \ldots, X^{(4)}_T\} & \\
    & \vdots & \\
    & \{X^{(j)}_1, X^{(j)}_2, \ldots, X^{(j)}_T\} & 
\end{eqnarray*}
```
Por lo mismo, cada cambio que se hace al vector $\{ X^{(1)}_t \}$ es
parte del mismo proceso estocástico, por lo que la serie de tiempo es:

```{=tex}
\begin{equation}
    \{ X_1, X_2, \ldots, X_T \}
        \label{variast}
\end{equation}
```
El proceso estocástico de dimensión $T$ puede ser completamente descrito
por su función de distribución multivariada de dimensión $T$. No
obstante, sólo nos enfocaremos en sus primer y segundo momentos, es
decir, en sus medias o valores esperados $\mathbb{E} (X_t)$

Para $t = 1, 2, \ldots, T$:

```{=tex}
\begin{equation*}
\left[
    \begin{array}{c}
    \mathbb{E}[X_1], \mathbb{E}[X_2], \ldots, \mathbb{E}[X_T]
    \end{array}
\right]
\end{equation*}
```

De sus variazas: 

\begin{equation*}
    Var[X_t] = \mathbb{E}[(X_t - \mathbb{E}[X_t])^2]
\end{equation*} Para $t = 1, 2, \ldots, T$, y de sus $T(T-1)/2$
covarianzas: \begin{equation*}
    Cov[X_t,X_s] = \mathbb{E}[(X_t - \mathbb{E}[X_t])(X_s - \mathbb{E}[X_s])]
\end{equation*}

Para $t < s$. Por lo tanto, en la forma matricial podemos escribir lo siguiente: 
\begin{equation*}
\left[
    \begin{array}{c c c c}
    Var[X_1] & Cov[X_1,X_2] & \cdots & Cov[X_1,X_T] \\
    Cov[X_2,X_1] & Var[X_2] & \cdots & Cov[X_2,X_T] \\
    \vdots & \vdots & \ddots & \vdots \\
    Cov[X_T,X_1] & Cov[X_T,X_2] & \cdots & Var[X_T] \\
    \end{array}
\right]
\end{equation*}

\begin{equation}
= \left[
    \begin{array}{c c c c}
    \sigma_1^2 & \rho_{12} & \cdots & \rho_{1T} \\
    \rho_{21} & \sigma_2^2 & \cdots & \rho_{2T} \\
    \vdots & \vdots & \ddots & \vdots \\
    \rho_{T1} & \rho_{T2} & \cdots & \sigma_T^2 \\
    \end{array}
\right]
(\#eq:MATCOV)
\end{equation}

Donde es claro que en la matriz de la ecuación \@ref(eq:MATCOV) existen $T(T-1)/2$ covarianzas distintas, ya que se cumple que $Cov[X_t,X_s] = Cov[X_s,X_t]$, para $t \neq s$. A menudo, esas covarianzas son denominadas como _autocovarianzas_ puesto que ellas son covarianzas entre variables aleatorias pertenecientes al mismo proceso estocástico pero en un momento $t$ diferente. Si el proceso estocástico tiene una distribución normal multivariada, su función de distribución estará totalmente descrita por sus momentos de primer y segundo orden.

### Ergocidad

Esto implica que los momentos muestrales, los cuales son calculados en la base de una serie de tiempo con un número finito de observaciones, conforme el tiempo $T \rightarrow \infty$ sus correspondientes momentos muestrales, tienden a los verdaderos valores poblacionales, los cuales definiremos como $\mu$, para la media, y $\sigma^2_X$ para la varianza. _En pocas palabras, conforme los momentos muestrales aumenten tanto que tiendan al infinito, entonces nos acercamos a valores poblacionales de la media y la varianza_.
 Este concepto sólo es cierto si asumimos que
 
\begin{eqnarray*}
    \mathbb{E}[X_t] = \mu_t = \mu \\
    Var[X_t] = \sigma^2_X
\end{eqnarray*} 
Más formalmente, se dice que el PGD o el proceso estocástico es ergódico en la media si:
\begin{equation}
    \displaystyle\lim_{T \to \infty}{\mathbb{E} \left[ \left( \frac{1}{T} \sum^{T}_{t = 1} (X_t - \mu) \right) ^2 \right]} = 0
\end{equation}

y ergódico en la varianza si:
\begin{equation}
    \displaystyle\lim_{T \to \infty}{\mathbb{E} \left[ \left( \frac{1}{T} \sum^{T}_{t = 1} (X_t - \mu) ^2 - \sigma^2_X \right) ^2 \right]} = 0
\end{equation}
+
Estas condiciones se les conoce como _propiedades de consistencia_ para las variables aleatorias. Sin embargo, éstas no pueden ser probadas. Por ello se les denomina como un supuesto que pueden cumplir algunas de las series. Más importante aún: **un proceso estocástico que tiende a estar en equilibrio estadístico en un orden ergódico, es estacionario**.

### Tipos de Estacionariedad

Definiremos a la estacionariedad por sus momentos del correspondiente proceso estocástico dado por $\{X_t\}$:

- _Estacionariedad en media_: Un proceso estocástico es estacionario en media si $E[X_t] = \mu_t = \mu$ es constante para todo $t$.

- _Estacionariedad en varianza_: Un proceso estocástico es estacionario en varianza si $Var[X_t] = \mathbb{E}[(X_t - \mu_t)^2] = \sigma^2_X = \gamma(0)$ es constante y finita para todo $t$.

- _Estacionariedad en covarianza_: Un proceso estocástico es estacionario en covarianza si $Cov[X_t,X_s] = \mathbb{E}[(X_t - \mu_t)(X_s - \mu_s)] = \gamma(|s-t|)$ es sólo una función del tiempo y de la distancia entre las dos variables aleatorias. Por lo que no depende del tiempo denotado por $t$ (no depende de la información contemporánea).

- _Estacionariedad débil_: Como la estacionariedad en varianza resulta de forma inmediata de la estacionariedad en covarianza cuando se asume que $s = t$, un proceso estocástico es débilmente estacionario cuando es estacionario en media y covarianza. __ESTE ES EL MÁS COMÚN Y POSIBLE__, por lo que es el que estudiaremos.

### Función de Autocorrelación (ACF)
Para ampliar la discusión, es posible calcular la fuerza o intensidad de la dependencia de las variables aleatorias dentro de un proceso estocástico, ello mediante el uso de las autocovarianzas. Cuando las covarianzas son normalizadas respecto de la varianza, el resultado es un término que es independiente de las unidad de medida aplicada, y se conoce como la _función de autocorrelación_.

Por su parte, un estimador consistente de la función de autocorrelación estará dado por:
\begin{equation}
    \hat{\rho}(\tau) = \frac{\sum^{T - \tau}_{t=1} (X_t - \hat{\mu})(X_{t+\tau} - \hat{\mu})}{\sum^T_{t=1} (X_t - \hat{\mu})^2} = \frac{\hat{\gamma}(\tau)}{\hat{\gamma}(0)} \mbox{, para } \tau = 1, 2, \ldots, T-1
    (\#eq:EqAutoCorr)
\end{equation}

El estimador de la ecuación \@ref(eq:EqAutoCorr) es asintóticamente insesgado y __es relevante puesto que nos dice si una serie de tiempo con estacionariedad débil  esta serialmente correlacionada si y solo si $\hat{\rho}(\tau)\neq0$__.

### Ruido Blanco

Supongamos una serie de tiempo denotada por: $\{U_t\}^T_{t = 0}$. Decimos que el proceso estocástico $\{U_t\}$ es un _proceso estocástico puramente aleatorio_ o es un _proceso estocástico de ruido blanco o caminata aleatoria_, si éste tiene las siguientes propiedades: 

- $\mathbb{E}[U_t] = 0$, $\forall t$
    
- $Var[U_t] = \mathbb{E}[(U_t - \mu_t)^2] = \mathbb{E}[(U_t - \mu)^2] = \mathbb{E}[(U_t)^2] = \sigma^2$, $\forall t$
    
- $Cov[U_t,U_s] = \mathbb{E}[(U_t - \mu_t)(U_s - \mu_s)] = \mathbb{E}[(U_t - \mu)(U_s - \mu)] = \mathbb{E}[U_t U_s] = 0$, $\forall t \neq s$.
- $\hat{\rho}(\tau)=0$

En palabras. Un proceso $U_t$ es un ruido blanco si su valor promedio es cero (0), tiene una varianza finita y constante, y además no le importa la historia pasada, así su valor presente no se ve influenciado por sus valores pasados no importando respecto de que periodo se tome referencia.

Para procesos estacionarios, dicha función de autocorrelación esta dada por:
\begin{equation}
    \rho(\tau) = \frac{\mathbb{E}[(X_t - \mu)(X_{t+\tau} - \mu)]}{\mathbb{E}[(X_t - \mu)^2]} = \frac{\gamma(\tau)}{\gamma(0)} 
\end{equation}

## Estimación
### Dependencias

```{r message=FALSE, warning=FALSE, warning=FALSE, message=FALSE}
#install.packages("pacman")
#pacman nos permite cargar varias librerias en una sola línea
library(pacman)
pacman::p_load(tidyverse,BatchGetSymbols,ggplot2,lubridate,readxl,forecast,stats)
```

## Caminata

```{r Caminata10, echo=TRUE, message=FALSE, warning=FALSE, results='asis', fig.cap="Ejemplo de 10 trayectorias de la caminata aleatoria, cuando sólo es posible cambios de +1 y -1", fig.align='center'}

set.seed(1234)
# Utilizaremos una función guardada en un archivo a parte
# Llamamos a la función:
source("funciones/Caminata.R")

# Definimos argumentos de la función
Opciones <- c(-1, 1)
#
Soporte <- 10000

# Vamos a réplicar el proceso con estos parámetros
Rango <- 200
#
Caminos <- 10

#

for(i in 1:Caminos){
  TT <- data.matrix(data.frame(Caminata(Opciones, Soporte)[1]))
  #
  G_t <- data.matrix(data.frame(Caminata(Opciones, Soporte)[2]))
  #
  plot(TT, G_t, col = "blue", type = "l", ylab = "Ganancias", xlab = "Tiempo", ylim = c(-Rango,Rango))
  #
  par(new = TRUE)
  #
  i <- i +1
}
#
par(new = FALSE)

```

Así, el proceso estocástico dado por la caminata alaeatoria sin un
término de ajuste es estacionario en media, pero no en varianza o en
covarianza, y consecuentemente, en general no estacionario, condición
que contraria al caso del proceso simple descrito en $U_t$.

Es facil ver que muchas de las posibilidades de realización de este
proceso estocástico (series de tiempo) pueden tomar cualquiera de las
rutas consideradas en el Figura \@ref(fig:Caminata10). Ahora analicemos
un solo camino.

## Un camino

```{r Caminata1, fig.cap="Una Caminata aleatoria cuando sólo es posible cambios de +1 y -1", warning=FALSE, message=FALSE}
#Generamos datos
  TT1 <- data.matrix(data.frame(Caminata(Opciones, Soporte)[1]))
  G_t1 <- data.matrix(data.frame(Caminata(Opciones, Soporte)[2]))
#Creemos un data frame
  dt_caminata<-data.frame(TT1,G_t1)
  colnames(dt_caminata)<-c("t","ganancias")
  head(dt_caminata)
#plot
  plot(TT1, G_t1, col = "blue", type = "l", ylab = "Ganancias", xlab = "Tiempo", ylim = c(-Rango,Rango))
```

Hay que convertirlo a serie de tiempo

```{r, echo=TRUE, results=FALSE}
#serie de tiempo
caminata_ts<-ts(G_t1,start=1,end=Soporte)
```

### Estacionariedad Caminata

```{r ACFCAMINATA1, fig.cap="Función de Autocorrelación de una Caminata", warning=FALSE, message=FALSE}
ACF_caminata_ts<-acf(caminata_ts,na.action = na.pass, main = "Función de Autocorrelación de una Caminata")
```

Como se comentó con anterioridad en la Figura \@ref(fig:ACFCAMINATA1) es
evidente que la Caminata si tiene autocorrelacion, por lo que nuestro
plot de autocorrelacion tiene valores muy altos en todos los lags.
Veamos los lags.

```{r LAGSCAMINATA1, fig.cap="Lags de una sola caminata", warning=FALSE, message=FALSE}
gglagplot(caminata_ts,lags=10,do.lines=FALSE,colour=FALSE)+theme_light()
```

De nuevo, esto al ser creado de manera estandarizada estamos seguros de
que va a ser estacionario en la medio, por lo mismo los lags de la
Figura \@ref(fig:LAGSCAMINATA1) se ven tan correlacionados.

## Precios de un activo

```{r, warning=FALSE, message=FALSE}
#Primero determinamos el lapso de tiempo
pd<-Sys.Date()-(365*20) #primer fecha
pd
ld<-Sys.Date() #última fecha
ld
#Intervalos de tiempo
int<-"monthly"
#Datos a elegir
dt<-c("AMZN")
dt2<-c("TSLA")
#Descargando los valores
data1<- BatchGetSymbols(tickers = dt,
                       first.date = pd,
                       last.date = ld,
                       freq.data = int,
                       do.cache = FALSE,
                       thresh.bad.data = 0)
#Generando data frame con los valores
data_precio_amzn<-data1$df.tickers
colnames(data_precio_amzn)

#necesitamos convertir la serie de tiempo de precios en retornos continuos compuestos de los precios de apertura
data_precio_amzn$ccrAMZN<-c(NA ,100*diff(log(data_precio_amzn$price.open)))#agregamos un valor NA al principio
data_precio_amzn$ccrAMZN#estos son los retornos
#tenemos 20 retornos a lo largo de 20 años
```

Veamos la serie de tiempo

```{r amazn20, fig.cap="Serie de tiempo de los retornos de año en los últimos 20 años", warning=FALSE, message=FALSE}
ret_20_amazn<-ggplot(data=data_precio_amzn, aes(x=ref.date))+geom_line(aes(y=ccrAMZN))+labs(title="Retornos de AMZN en los últimos 20 años",y="Retornos", x="Años")+theme_light()
ret_20_amazn
```

### Serie de tiempo

Primero que nada es importante cargar los datos a un objeto series de
tiempo. Esto nos lo permite la función ts(). Además debemos serciorarnos
de que los datos esten en orden cronológico.

```{r, warning=FALSE, message=FALSE}
data_precio_amzn<-data_precio_amzn[order(data_precio_amzn$ref.date),]
head(data_precio_amzn)#dado que ya estaba en orden cronológico nuestro df no cambia
#hagamos el objeto ts
ret_amazn_ts<-ts(data_precio_amzn$ccrAMZN)
plot(ret_amazn_ts)#de esta manera podemos ver que se cargo bien debido a que es igual al ggplot
```

### Estacionariedad

```{r amazn20LAG, fig.cap="Lag Plot que nos muestra la correlación entre 20 lags", warning=FALSE, message=FALSE}
#MA_m5<-forecast::ma(ret_amazn_ts,order=11,centre=TRUE)
#plot(ret_amazn_ts)+lines(MA_m5, col="red", lwd=2)
gglagplot(ret_amazn_ts,lags=20,do.lines=FALSE,colour=FALSE)+theme_light()
```

```{r amazn20ACF, fig.cap="Función de Autocorrelación de los retornos de AMZN en los ultimos 20 años", warning=FALSE, message=FALSE}
ACF_ret_amazn_ts<-acf(ret_amazn_ts,na.action = na.pass)
```

La Figura \@ref(fig:amazn20LAG) nos idica la manera en la que se
correlacionan los lags, evidentemente no se puede ver ningún tipo de
correlacioo1ón visible. Similarmente la Figura \@ref(fig:amazn20ACF) en
donde se muestra la función de autocorrelación. Expecto al primer lag
--que muestra correlacion debido a que se esta comparando consigo
mismo-- es evidente que no hay correlacioo1ón fuerte entre ninguno de
los lags. Por lo mismo, sería difícil poder encontrar y estimar valores
futuros debido a que la Figura \@ref(fig:amazn20LAG) y la Figura
\@ref(fig:amazn20ACF) indican que la serie de tiempo de los retornos de
AMZN de la Figura \@ref(fig:amazn20) es **completamente aleatorio y no
hay estacionariedad**.
