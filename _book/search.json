[{"path":"index.html","id":"mínimos-cuadrados-ordinarios","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1 Mínimos Cuadrados Ordinarios","text":"","code":""},{"path":"index.html","id":"el-problema","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.1 El problema","text":"Recordando que el método de MCO resulta en encontrar la combinación de valores de los estimadores de los parámetros \\(\\hat{\\boldsymbol{\\beta}}\\) que permita minimizar la suma de los residuales (estimadores de los términos de erro \\(\\boldsymbol{\\varepsilon}\\)) al cuadrado dada por:\\[\n    \\sum^{N}_{=1}{e^2_i} = \\sum^{N}_{= 1}{(y_i - \\mathbf{X}'_i \\hat{\\boldsymbol{\\beta}})^2}\n\\]Donde \\(\\hat{\\boldsymbol{\\beta}}\\) denota el vector de estimadores \\(\\hat{\\beta}_1, \\ldots, \\hat{\\beta}_K\\) y dado que \\((e_1, e_2, \\ldots, e_n)'(e_1, e_2, \\ldots, e_n) = {\\mathbf{e'e}}\\), el problema del método de MCO consiste en resolver el problema de óptimización:\\[\\begin{eqnarray*}\nMinimizar_{\\hat{\\boldsymbol \\beta}} S(\\hat{\\boldsymbol \\beta})  =  Minimizar_{\\hat{\\boldsymbol \\beta}} \\mathbf{e'e} \\\\\n    =  Minimizar_{\\hat{\\boldsymbol \\beta}} (\\mathbf{Y}-\\mathbf{X}\\hat{\\boldsymbol \\beta})'(\\mathbf{Y}-\\mathbf{X}\\hat{\\boldsymbol \\beta})\n\\end{eqnarray*}\\]Expandiendo la expresión \\(\\mathbf{e'e}\\) obtenemos:\n\\[\n    \\mathbf{e'e} = \\mathbf{Y'Y} - 2 \\mathbf{Y'X} \\hat{\\boldsymbol \\beta} + \\hat{\\boldsymbol \\beta}' \\mathbf{X'X}\\hat{\\boldsymbol \\beta}\n\\]De esta forma obtenemos que las condiciones necesarias de un mínimo son:\\[\n    \\frac{\\partial S(\\hat{\\boldsymbol \\beta})}{\\partial \\hat{\\boldsymbol \\beta}} = -2{\\mathbf{X'Y}} + 2{\\mathbf{X'X}} \\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\n\\]\nY se pueden despejar las dadas por:Debido que el objetivo es encontrar la matriz \\(\\hat{\\boldsymbol\\beta}\\) despejamos:\\[\\hat{\\boldsymbol \\beta} = (\\mathbf{X'X})^{-1}\\mathbf{X'Y}\n\\]\n\\[\n    \\mathbf{X'X}\\hat{\\boldsymbol \\beta} = \\mathbf{X'Y}\n\\]","code":""},{"path":"index.html","id":"estimación-r","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2 Estimación R","text":"Para la estimación utilizaremos el paquete “BatchGetSymbols”. Este paquete nos permitirá descargar información acerca de la bolsa de valores internacional.","code":""},{"path":"index.html","id":"dependencias","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.1 Dependencias","text":"","code":"\n#install.packages(\"pacman\")\n#pacman nos permite cargar varias librerias en una sola línea\nlibrary(pacman)\npacman::p_load(tidyverse,BatchGetSymbols,ggplot2, lubridate)"},{"path":"index.html","id":"descarga-de-los-valores","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.2 Descarga de los valores","text":"","code":"\n#Primero determinamos el lapso de tiempo\npd<-Sys.Date()-365 #primer fecha\npd\n#> [1] \"2021-09-06\"\nld<-Sys.Date() #última fecha\nld\n#> [1] \"2022-09-06\"\n#Intervalos de tiempo\nint<-\"monthly\"\n#Datos a elegir\ndt<-c(\"AMZN\")\n\n#Descargando los valores\n?BatchGetSymbols()\ndata<- BatchGetSymbols(tickers = dt,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n\n#Generando data frame con los valores\ndata_precio<-data$df.tickers\ncolnames(data_precio)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\""},{"path":"index.html","id":"gráficas","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.3 Gráficas","text":"","code":"\nsp_precio<-ggplot(data_precio, aes(x=ref.date, y=price.open))+geom_point(size =2, colour = \"black\")+labs(x=\"Fecha\", y=\"Precio de apertura (USD)\", title=\"Precio de apertura de AMZN en el ultimo año\")+ theme_light()+ geom_smooth(method = lm, se = TRUE)\nsp_precio\n\nsp_volumen<-ggplot(data_precio, aes(x=ref.date, y=volume))+geom_point(size =2, colour = \"black\")+labs(x=\"Fecha\", y=\"Volumen\", title=\"Volumenes de AMZN en el ultimo año\")+ theme_light()+ geom_smooth(method = lm, se = TRUE)\nsp_volumen"},{"path":"index.html","id":"regresión-lineal-que-optiene-los-coeficientes-hatboldsymbol-beta","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.4 Regresión lineal que optiene los coeficientes \\(\\hat{\\boldsymbol \\beta}\\)","text":"","code":"\n#datos estadísticos\nsummary(data_precio[c(\"price.open\",\"volume\")])\n#>    price.open        volume         \n#>  Min.   :106.3   Min.   :1.140e+08  \n#>  1st Qu.:126.0   1st Qu.:1.273e+09  \n#>  Median :152.7   Median :1.465e+09  \n#>  Mean   :148.5   Mean   :1.392e+09  \n#>  3rd Qu.:167.6   3rd Qu.:1.628e+09  \n#>  Max.   :177.2   Max.   :2.258e+09\n#análisis de regresión lineal lm() y=precio,x=fecha\nreg_tiempo_precio<-lm(price.open~ref.date, data=data_precio) \n#¡Siempre se pone dentro de lm() la variable dependiente primero y luego la independiete!\nsummary(reg_tiempo_precio)\n#> \n#> Call:\n#> lm(formula = price.open ~ ref.date, data = data_precio)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -21.9379  -9.7257  -0.8686   9.1948  20.6055 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3355.37814  615.12157   5.455 0.000199 ***\n#> ref.date      -0.16831    0.03228  -5.214 0.000288 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 13.13 on 11 degrees of freedom\n#> Multiple R-squared:  0.7119, Adjusted R-squared:  0.6857 \n#> F-statistic: 27.18 on 1 and 11 DF,  p-value: 0.0002884\n\n#análisis de regresión lineal lm() y=volumen,x=fecha\nreg_tiempo_volumen<-lm(volume~ref.date, data=data_precio)\nsummary(reg_tiempo_volumen)\n#> \n#> Call:\n#> lm(formula = volume ~ ref.date, data = data_precio)\n#> \n#> Residuals:\n#>        Min         1Q     Median         3Q        Max \n#> -1.133e+09 -1.780e+08  4.137e+07  2.347e+08  9.141e+08 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)  1.659e+10  2.358e+10   0.704    0.496\n#> ref.date    -7.978e+05  1.237e+06  -0.645    0.532\n#> \n#> Residual standard error: 503100000 on 11 degrees of freedom\n#> Multiple R-squared:  0.03641,    Adjusted R-squared:  -0.05119 \n#> F-statistic: 0.4157 on 1 and 11 DF,  p-value: 0.5323"},{"path":"index.html","id":"ejercicio","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3 Ejercicio","text":"El objetivo de este ejrcicio es simplemente que indiquen y modifiquen los errores en el código. Así pues, deberán descomentar -quitar las #antes del código- para empezar el ejercicio.","code":""},{"path":"index.html","id":"section","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.1 1","text":"El objetivo de este código es explicar la variable “volume” con la variable “price.high”.","code":"\n#reg_tiempo_ej1<-lm(price.high~volume, data=data_precio)\n#sumary(reg_tiempo_ej1)"},{"path":"index.html","id":"section-1","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.2 2","text":"El objetivo de este código es explicar la variable “volume” con la variable “price.low”.","code":"\n#reg_tiempo_ej2<-lm(price.low~volume, data=data_precio)\n#summary(reg_tiempo_ej1)"},{"path":"index.html","id":"opcional","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.3 3 (opcional)","text":"El objetivo de este ejercicio es descargar los valores del stock de Tesla BMV: TSLA en los últimos dos años.","code":"\n#dt_ej3<-(\"TSLA\")\n#pdej<-Sys.Date()-(365*3) #primer fecha\n#pdej\n#Descargando los valores\n#dataej3<- BatchgetSymbols(tickers = dt_ej3,\n                       #first.date = pdej,\n                       #last.date = ld,\n                       #freq.data = int,\n                       #do.cache = FALSE,\n                       #thresh.bad.data = 0)\n\n#Generando data frame con los valores\n#data_precio_ej2<-dataej3$df.tickers\n#1colnames(data_precio_ej2)"},{"path":"máxima-verosimilitud.html","id":"máxima-verosimilitud","chapter":"2 Máxima Verosimilitud","heading":"2 Máxima Verosimilitud","text":"","code":""},{"path":"máxima-verosimilitud.html","id":"el-problema-1","chapter":"2 Máxima Verosimilitud","heading":"2.1 El problema","text":"Recordemos que dado \\(f(y_i | \\mathbf{x}_i)\\) la función de densidad condicional de \\(y_i\\) dado \\(\\mathbf{x}_i\\). Sea \\(\\boldsymbol{\\theta}\\) un conjunto de parámetros de la función. Entonces la función de densidad conjunta de variables aleatorias independientes \\(\\{ y_i : y_i \\\\mathbb{R} \\}\\) dados los valores \\(\\{ \\mathbf{x}_i : \\mathbf{x}_i \\\\mathbb{R}^K \\}\\) estará dada por:\\[\\begin{equation}\n    \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = f(y_1, y_2, \\ldots, y_n | \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n; \\boldsymbol{\\theta}) = L(\\boldsymbol{\\theta})\n    \\tag{2.1}\n\\end{equation}\\]la ecuación (2.1) se le conoce como ecuación de verosimilitud. El problema de máxima verosimilitud entonces será:\n\\[\\begin{equation}\n    \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} L(\\boldsymbol{\\theta})\n        \\tag{2.2}\n\\end{equation}\\]Dado que el logaritmo natural es una transformación monotona, podemos decir que el problema de la ecuación (2.2) es equivalente :\\[\\begin{equation}\n     \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} ln L(\\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} ln \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} \\sum_{= 1}^{n} ln f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta})\n            \\tag{2.3}\n\\end{equation}\\]Para solucionnar el problema se tiene que determinar las condicones de primer y segundo orden, las cuales serán:\n\\[\\begin{equation}\n    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) = \\nabla ln L(\\boldsymbol{\\theta})\n          \\tag{2.4}\n\\end{equation}\\]\\[\\begin{equation}\n    \\frac{\\partial^2}{\\partial^2 \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) \\cdot  \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}') = H(\\boldsymbol{\\theta})\n             \\tag{2.5}\n\\end{equation}\\]La solución estará dada por aquel valor de \\(\\hat{\\boldsymbol{\\theta}}\\) que hace:\n\\[\\begin{equation*}\n    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\hat{\\boldsymbol{\\theta}}) = 0\n\\end{equation*}\\]su vez, la varianza será aquella que resulta de:\n\\[\\begin{equation*}\n    Var[\\hat{\\boldsymbol{\\theta}} | \\mathbf{X}] = \\left( - \\mathbb{E}_{\\hat{\\boldsymbol{\\theta}}}[H(\\boldsymbol{\\theta})] \\right)^{-1}\n\\end{equation*}\\]","code":""},{"path":"máxima-verosimilitud.html","id":"estimación-y-simunlación","chapter":"2 Máxima Verosimilitud","heading":"2.2 Estimación y simunlación","text":"","code":""},{"path":"máxima-verosimilitud.html","id":"lanzar-una-moneda","chapter":"2 Máxima Verosimilitud","heading":"2.2.1 Lanzar una moneda","text":"Si bien el ejercicio anterior es un tanto repetitivo debido que sabemos que hay un 50% de que caiga una moneda de un lado o otro. Esto ejemplifica la manera en la que se utiliza el metodo de maximización de máxima verosimilitud.","code":"\nset.seed(1234)#esto sirve para siempre generar los mismos numeros aleatorios\n#rbinom(numero observaciones,numero de ensayos,probabilidad de exito en cada ensayo)\ncara<-rbinom(1,100,0.5)\ncara#esto nos dice de los 100 ensayos cuantos fueron cara\n#> [1] 47\nsol<-100-cara\nsol\n#> [1] 53\n\n\n#Ahora definiremos la función que encontrará la función de verosimilutud para determinado valor p\n#\nverosimilitud <- function(p){\n  dbinom(cara, 100, p)\n}\n\n#si suponemos que la probabilidad sesgada de que caiga cara es 40%\nprob_sesgada<-0.4\n#es posible calcular la función de que salga cara\nverosimilitud(prob_sesgada)\n#> [1] 0.02919091\n#ahora es posible generar una función de verimilitud negativa \n#para maximizar el valor de la verosimilitud\nneg_verosimilitud <- function(p){\n  dbinom(cara, 100, p)*-1\n}\nneg_verosimilitud(prob_sesgada)\n#> [1] -0.02919091\n# unamos la función nlm() para maximizar esta función no linear\n#?nlm()\nnlm(neg_verosimilitud,0.5,stepmax=0.5)#se pone un parametro porque sabemos que hay un 0.5 de probabilidad de que caiga cara\n#> $minimum\n#> [1] -0.07973193\n#> \n#> $estimate\n#> [1] 0.47\n#> \n#> $gradient\n#> [1] 1.589701e-10\n#> \n#> $code\n#> [1] 1\n#> \n#> $iterations\n#> [1] 4"},{"path":"método-generalizado-de-momentos-mgm.html","id":"método-generalizado-de-momentos-mgm","chapter":"3 Método Generalizado de Momentos (MGM)","heading":"3 Método Generalizado de Momentos (MGM)","text":"","code":""},{"path":"método-generalizado-de-momentos-mgm.html","id":"el-problema-2","chapter":"3 Método Generalizado de Momentos (MGM)","heading":"3.1 El problema","text":"Retomemos el modelo de regresión lineal tal que:\\[\\begin{equation}\ny_i=X_i\\beta+u_i\n    \\label{Eq_reglin}\n\\end{equation}\\]Tomando en cuenta los principios de ortogonalidad (\\(E(Z_iu_i)=0\\)) y (\\(rankE(Z_i^{'}X_i)=0\\)) sabemos que \\(\\beta\\) es el único vector de \\(N\\times1\\) que resuelve las condiciones de momento de determinada población. En otras palabras, \\(E[z_i^{'}(y_i-x_i\\beta)]=0\\) es una solución y \\(E[z_i^{'}(y_i-x_i\\beta)]\\neq0\\) es una solución. Debido que la media muestral son estimadores consistentes de momentos de una población, se puede:\\[\\begin{equation}\nN^{-1}\\sum_{=1}^{N}z_i^{'}(y_i-x_i\\beta)=0\n\\tag{3.1}\n\\end{equation}\\]Asumiendo que la ecuación (3.1) tiene L ecuaciones lineales y K coeficientes \\(\\beta\\) desconocidos y \\(K=L\\), entonces la matriz \\(\\sum_{=1}^{N}z_i^{'}x_i\\) debe ser singular para encontrar los coeficientes de la siguiente manera.\\[\\begin{equation}\n\\hat{\\beta}=N^{-1}\\left[\\sum_{=1}^{N}z_i^{'}x_i\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_i\\right]\n\\tag{3.2}\n\\end{equation}\\]Para simplificar (3.2) se puede nombrar Z juntando \\(z_i\\) N veces para crear una matriz de tamaño \\(NG\\times L\\). Lo mismo hacemos con X juntando \\(x_i\\) para obtener una de \\(NG\\times K\\) y Y obteniendo una \\(NG\\times 1\\). Obteniendo:\\[\\begin{equation}\n\\hat{\\beta}=[Z^{'}X]^{-1}[Z^{'}Y]\n\\end{equation}\\]Es importante tomar en cuenta cuando el caso en el que hay más ecuaciones lineales que coeficientes \\(\\beta\\); es decir, \\(L\\geq K\\). En estos casos es muy probrable que haya solución, por lo que mejor que se puede estimar es pones la ecuación (3.1), tan pequeña como sea posible. Por lo mismo el paso que nos lleva la ecuación (3.2), debe eliminarse \\(N^{-1}\\). El objetivo:\\[\\begin{equation}\n\\min_{\\beta} \\left[\\sum_{=1}^{N}z_i^{'}x_i\\beta\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_i\\beta\\right]\n\\tag{3.3}\n\\end{equation}\\]Así pues nombramos W como una matriz simétrica de \\(W\\times W\\) donde se genera la variable \\(b\\) que debemos minimizar que sustituye \\(\\beta\\) creando una función cuadrática en la ecuación (3.2).\n\\[\\begin{equation}\n\\min_{b}\\left[\\sum_{=1}^{N}z_i^{'}x_ib\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_ib\\right]\n\\tag{3.4}\n\\end{equation}\\]\\[\\begin{equation}\n\\therefore\\hat{\\beta}=[X^{'}Z\\hat{W}Z^{'}X]^{-1}[X^{'}Z\\hat{W}Z^{'}Y]\n\\end{equation}\\]Sin embargo, \\(X^{'}Z\\hat{W}Z^{'}X\\) debe ser singular para que haya una solución. Para esto se asume que \\(\\hat{W}\\) tiene un limite de probabilidad singular. Esto se describe como \\(\\hat{W}\\xrightarrow[]{p}W\\) y \\(N\\xrightarrow[]{}W\\infty\\) donde \\(W\\) es aleatorio, es una matriz positiva definida simétrica de \\(L\\times L\\).","code":""}]
