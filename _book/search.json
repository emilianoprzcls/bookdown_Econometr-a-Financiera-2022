[{"path":"index.html","id":"mínimos-cuadrados-ordinarios","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1 Mínimos Cuadrados Ordinarios","text":"","code":""},{"path":"index.html","id":"el-problema","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.1 El problema","text":"Recordando que el método de MCO resulta en encontrar la combinación de valores de los estimadores de los parámetros \\(\\hat{\\boldsymbol{\\beta}}\\) que permita minimizar la suma de los residuales (estimadores de los términos de erro \\(\\boldsymbol{\\varepsilon}\\)) al cuadrado dada por:\\[\n    \\sum^{N}_{=1}{e^2_i} = \\sum^{N}_{= 1}{(y_i - \\mathbf{X}'_i \\hat{\\boldsymbol{\\beta}})^2}\n\\]Donde \\(\\hat{\\boldsymbol{\\beta}}\\) denota el vector de estimadores \\(\\hat{\\beta}_1, \\ldots, \\hat{\\beta}_K\\) y dado que \\((e_1, e_2, \\ldots, e_n)'(e_1, e_2, \\ldots, e_n) = {\\mathbf{e'e}}\\), el problema del método de MCO consiste en resolver el problema de óptimización:\\[\\begin{eqnarray*}\nMinimizar_{\\hat{\\boldsymbol \\beta}} S(\\hat{\\boldsymbol \\beta})  =  Minimizar_{\\hat{\\boldsymbol \\beta}} \\mathbf{e'e} \\\\\n    =  Minimizar_{\\hat{\\boldsymbol \\beta}} (\\mathbf{Y}-\\mathbf{X}\\hat{\\boldsymbol \\beta})'(\\mathbf{Y}-\\mathbf{X}\\hat{\\boldsymbol \\beta})\n\\end{eqnarray*}\\]Expandiendo la expresión \\(\\mathbf{e'e}\\) obtenemos:\n\\[\n    \\mathbf{e'e} = \\mathbf{Y'Y} - 2 \\mathbf{Y'X} \\hat{\\boldsymbol \\beta} + \\hat{\\boldsymbol \\beta}' \\mathbf{X'X}\\hat{\\boldsymbol \\beta}\n\\]De esta forma obtenemos que las condiciones necesarias de un mínimo son:\\[\n    \\frac{\\partial S(\\hat{\\boldsymbol \\beta})}{\\partial \\hat{\\boldsymbol \\beta}} = -2{\\mathbf{X'Y}} + 2{\\mathbf{X'X}} \\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\n\\]\nY se pueden despejar las dadas por:Debido que el objetivo es encontrar la matriz \\(\\hat{\\boldsymbol\\beta}\\) despejamos:\\[\\hat{\\boldsymbol \\beta} = (\\mathbf{X'X})^{-1}\\mathbf{X'Y}\n\\]\n\\[\n    \\mathbf{X'X}\\hat{\\boldsymbol \\beta} = \\mathbf{X'Y}\n\\]","code":""},{"path":"index.html","id":"estimación-r","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2 Estimación R","text":"Para la estimación utilizaremos el paquete “BatchGetSymbols”. Este paquete nos permitirá descargar información acerca de la bolsa de valores internacional.","code":""},{"path":"index.html","id":"dependencias","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.1 Dependencias","text":"","code":"\n#install.packages(\"pacman\")\n#pacman nos permite cargar varias librerias en una sola línea\nlibrary(pacman)\npacman::p_load(tidyverse,BatchGetSymbols,ggplot2, lubridate)"},{"path":"index.html","id":"descarga-de-los-valores","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.2 Descarga de los valores","text":"","code":"\n#Primero determinamos el lapso de tiempo\npd<-Sys.Date()-365 #primer fecha\npd\n#> [1] \"2021-09-28\"\nld<-Sys.Date() #última fecha\nld\n#> [1] \"2022-09-28\"\n#Intervalos de tiempo\nint<-\"monthly\"\n#Datos a elegir\ndt<-c(\"AMZN\")\n\n#Descargando los valores\n?BatchGetSymbols()\ndata<- BatchGetSymbols(tickers = dt,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n\n#Generando data frame con los valores\ndata_precio<-data$df.tickers\ncolnames(data_precio)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\""},{"path":"index.html","id":"gráficas","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.3 Gráficas","text":"","code":"\nsp_precio<-ggplot(data_precio, aes(x=ref.date, y=price.open))+geom_point(size =2, colour = \"black\")+labs(x=\"Fecha\", y=\"Precio de apertura (USD)\", title=\"Precio de apertura de AMZN en el ultimo año\")+ theme_light()+ geom_smooth(method = lm, se = TRUE)\nsp_precio\n\nsp_volumen<-ggplot(data_precio, aes(x=ref.date, y=volume))+geom_point(size =2, colour = \"black\")+labs(x=\"Fecha\", y=\"Volumen\", title=\"Volumenes de AMZN en el ultimo año\")+ theme_light()+ geom_smooth(method = lm, se = TRUE)\nsp_volumen"},{"path":"index.html","id":"regresión-lineal-que-optiene-los-coeficientes-hatboldsymbol-beta","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.2.4 Regresión lineal que optiene los coeficientes \\(\\hat{\\boldsymbol \\beta}\\)","text":"","code":"\n#datos estadísticos\nsummary(data_precio[c(\"price.open\",\"volume\")])\n#>    price.open        volume         \n#>  Min.   :106.3   Min.   :1.967e+08  \n#>  1st Qu.:126.0   1st Qu.:1.273e+09  \n#>  Median :152.7   Median :1.465e+09  \n#>  Mean   :148.0   Mean   :1.396e+09  \n#>  3rd Qu.:167.6   3rd Qu.:1.628e+09  \n#>  Max.   :177.2   Max.   :2.258e+09\n#análisis de regresión lineal lm() y=precio,x=fecha\nreg_tiempo_precio<-lm(price.open~ref.date, data=data_precio) \n#¡Siempre se pone dentro de lm() la variable dependiente primero y luego la independiete!\nsummary(reg_tiempo_precio)\n#> \n#> Call:\n#> lm(formula = price.open ~ ref.date, data = data_precio)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -21.9717  -9.2427  -0.4443   9.4999  20.7440 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3319.11669  633.04069   5.243 0.000275 ***\n#> ref.date      -0.16642    0.03322  -5.009 0.000397 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 13.22 on 11 degrees of freedom\n#> Multiple R-squared:  0.6952, Adjusted R-squared:  0.6675 \n#> F-statistic: 25.09 on 1 and 11 DF,  p-value: 0.0003966\n\n#análisis de regresión lineal lm() y=volumen,x=fecha\nreg_tiempo_volumen<-lm(volume~ref.date, data=data_precio)\nsummary(reg_tiempo_volumen)\n#> \n#> Call:\n#> lm(formula = volume ~ ref.date, data = data_precio)\n#> \n#> Residuals:\n#>        Min         1Q     Median         3Q        Max \n#> -1.036e+09 -1.820e+08  3.993e+07  2.482e+08  8.011e+08 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)\n#> (Intercept) -1.846e+10  2.299e+10  -0.803    0.439\n#> ref.date     1.042e+06  1.206e+06   0.864    0.406\n#> \n#> Residual standard error: 480100000 on 11 degrees of freedom\n#> Multiple R-squared:  0.06349,    Adjusted R-squared:  -0.02165 \n#> F-statistic: 0.7457 on 1 and 11 DF,  p-value: 0.4063"},{"path":"index.html","id":"ejercicio","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3 Ejercicio","text":"El objetivo de este ejrcicio es simplemente que indiquen y modifiquen los errores en el código. Así pues, deberán descomentar -quitar las #antes del código- para empezar el ejercicio.","code":""},{"path":"index.html","id":"section","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.1 1","text":"El objetivo de este código es explicar la variable “volume” con la variable “price.high”.","code":"\n#reg_tiempo_ej1<-lm(price.high~volume, data=data_precio)\n#sumary(reg_tiempo_ej1)"},{"path":"index.html","id":"section-1","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.2 2","text":"El objetivo de este código es explicar la variable “volume” con la variable “price.low”.","code":"\n#reg_tiempo_ej2<-lm(price.low~volume, data=data_precio)\n#summary(reg_tiempo_ej1)"},{"path":"index.html","id":"opcional","chapter":"1 Mínimos Cuadrados Ordinarios","heading":"1.3.3 3 (opcional)","text":"El objetivo de este ejercicio es descargar los valores del stock de Tesla BMV: TSLA en los últimos dos años.","code":"\n#dt_ej3<-(\"TSLA\")\n#pdej<-Sys.Date()-(365*3) #primer fecha\n#pdej\n#Descargando los valores\n#dataej3<- BatchgetSymbols(tickers = dt_ej3,\n                       #first.date = pdej,\n                       #last.date = ld,\n                       #freq.data = int,\n                       #do.cache = FALSE,\n                       #thresh.bad.data = 0)\n\n#Generando data frame con los valores\n#data_precio_ej2<-dataej3$df.tickers\n#1colnames(data_precio_ej2)"},{"path":"máxima-verosimilitud.html","id":"máxima-verosimilitud","chapter":"2 Máxima Verosimilitud","heading":"2 Máxima Verosimilitud","text":"","code":""},{"path":"máxima-verosimilitud.html","id":"el-problema-1","chapter":"2 Máxima Verosimilitud","heading":"2.1 El problema","text":"Recordemos que dado \\(f(y_i | \\mathbf{x}_i)\\) la función de densidad condicional de \\(y_i\\) dado \\(\\mathbf{x}_i\\). Sea \\(\\boldsymbol{\\theta}\\) un conjunto de parámetros de la función. Entonces la función de densidad conjunta de variables aleatorias independientes \\(\\{ y_i : y_i \\\\mathbb{R} \\}\\) dados los valores \\(\\{ \\mathbf{x}_i : \\mathbf{x}_i \\\\mathbb{R}^K \\}\\) estará dada por:\\[\\begin{equation}\n    \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = f(y_1, y_2, \\ldots, y_n | \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n; \\boldsymbol{\\theta}) = L(\\boldsymbol{\\theta})\n    \\tag{2.1}\n\\end{equation}\\]la ecuación (2.1) se le conoce como ecuación de verosimilitud. El problema de máxima verosimilitud entonces será:\n\\[\\begin{equation}\n    \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} L(\\boldsymbol{\\theta})\n        \\tag{2.2}\n\\end{equation}\\]Dado que el logaritmo natural es una transformación monotona, podemos decir que el problema de la ecuación (2.2) es equivalente :\\[\\begin{equation}\n     \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} ln L(\\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} ln \\Pi_{= 1}^{n} f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta}) = \\max_{\\boldsymbol{\\theta} \\\\boldsymbol{\\Theta}} \\sum_{= 1}^{n} ln f(y_i | \\mathbf{x}_i; \\boldsymbol{\\theta})\n            \\tag{2.3}\n\\end{equation}\\]Para solucionnar el problema se tiene que determinar las condicones de primer y segundo orden, las cuales serán:\n\\[\\begin{equation}\n    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) = \\nabla ln L(\\boldsymbol{\\theta})\n          \\tag{2.4}\n\\end{equation}\\]\\[\\begin{equation}\n    \\frac{\\partial^2}{\\partial^2 \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}) \\cdot  \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\boldsymbol{\\theta}') = H(\\boldsymbol{\\theta})\n             \\tag{2.5}\n\\end{equation}\\]La solución estará dada por aquel valor de \\(\\hat{\\boldsymbol{\\theta}}\\) que hace:\n\\[\\begin{equation*}\n    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} ln L(\\hat{\\boldsymbol{\\theta}}) = 0\n\\end{equation*}\\]su vez, la varianza será aquella que resulta de:\n\\[\\begin{equation*}\n    Var[\\hat{\\boldsymbol{\\theta}} | \\mathbf{X}] = \\left( - \\mathbb{E}_{\\hat{\\boldsymbol{\\theta}}}[H(\\boldsymbol{\\theta})] \\right)^{-1}\n\\end{equation*}\\]","code":""},{"path":"máxima-verosimilitud.html","id":"estimación-y-simunlación","chapter":"2 Máxima Verosimilitud","heading":"2.2 Estimación y simunlación","text":"","code":""},{"path":"máxima-verosimilitud.html","id":"lanzar-una-moneda","chapter":"2 Máxima Verosimilitud","heading":"2.2.1 Lanzar una moneda","text":"Si bien el ejercicio anterior es un tanto repetitivo debido que sabemos que hay un 50% de que caiga una moneda de un lado o otro. Esto ejemplifica la manera en la que se utiliza el metodo de maximización de máxima verosimilitud.","code":"\nset.seed(1234)#esto sirve para siempre generar los mismos numeros aleatorios\n#rbinom(numero observaciones,numero de ensayos,probabilidad de exito en cada ensayo)\ncara<-rbinom(1,100,0.5)\ncara#esto nos dice de los 100 ensayos cuantos fueron cara\n#> [1] 47\nsol<-100-cara\nsol\n#> [1] 53\n\n\n#Ahora definiremos la función que encontrará la función de verosimilutud para determinado valor p\n#\nverosimilitud <- function(p){\n  dbinom(cara, 100, p)\n}\n\n#si suponemos que la probabilidad sesgada de que caiga cara es 40%\nprob_sesgada<-0.4\n#es posible calcular la función de que salga cara\nverosimilitud(prob_sesgada)\n#> [1] 0.02919091\n#ahora es posible generar una función de verimilitud negativa \n#para maximizar el valor de la verosimilitud\nneg_verosimilitud <- function(p){\n  dbinom(cara, 100, p)*-1\n}\nneg_verosimilitud(prob_sesgada)\n#> [1] -0.02919091\n# unamos la función nlm() para maximizar esta función no linear\n#?nlm()\nnlm(neg_verosimilitud,0.5,stepmax=0.5)#se pone un parametro porque sabemos que hay un 0.5 de probabilidad de que caiga cara\n#> $minimum\n#> [1] -0.07973193\n#> \n#> $estimate\n#> [1] 0.47\n#> \n#> $gradient\n#> [1] 1.589701e-10\n#> \n#> $code\n#> [1] 1\n#> \n#> $iterations\n#> [1] 4"},{"path":"método-generalizado-de-momentos-mgm.html","id":"método-generalizado-de-momentos-mgm","chapter":"3 Método Generalizado de Momentos (MGM)","heading":"3 Método Generalizado de Momentos (MGM)","text":"","code":""},{"path":"método-generalizado-de-momentos-mgm.html","id":"el-problema-2","chapter":"3 Método Generalizado de Momentos (MGM)","heading":"3.1 El problema","text":"Retomemos el modelo de regresión lineal tal que:\\[\\begin{equation}\ny_i=X_i\\beta+u_i\n    \\label{Eq_reglin}\n\\end{equation}\\]Tomando en cuenta los principios de ortogonalidad (\\(E(Z_iu_i)=0\\)) y (\\(rankE(Z_i^{'}X_i)=0\\)) sabemos que \\(\\beta\\) es el único vector de \\(N\\times1\\) que resuelve las condiciones de momento de determinada población. En otras palabras, \\(E[z_i^{'}(y_i-x_i\\beta)]=0\\) es una solución y \\(E[z_i^{'}(y_i-x_i\\beta)]\\neq0\\) es una solución. Debido que la media muestral son estimadores consistentes de momentos de una población, se puede:\\[\\begin{equation}\nN^{-1}\\sum_{=1}^{N}z_i^{'}(y_i-x_i\\beta)=0\n\\tag{3.1}\n\\end{equation}\\]Asumiendo que la ecuación (3.1) tiene L ecuaciones lineales y K coeficientes \\(\\beta\\) desconocidos y \\(K=L\\), entonces la matriz \\(\\sum_{=1}^{N}z_i^{'}x_i\\) debe ser singular para encontrar los coeficientes de la siguiente manera.\\[\\begin{equation}\n\\hat{\\beta}=N^{-1}\\left[\\sum_{=1}^{N}z_i^{'}x_i\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_i\\right]\n\\tag{3.2}\n\\end{equation}\\]Para simplificar (3.2) se puede nombrar Z juntando \\(z_i\\) N veces para crear una matriz de tamaño \\(NG\\times L\\). Lo mismo hacemos con X juntando \\(x_i\\) para obtener una de \\(NG\\times K\\) y Y obteniendo una \\(NG\\times 1\\). Obteniendo:\\[\\begin{equation}\n\\hat{\\beta}=[Z^{'}X]^{-1}[Z^{'}Y]\n\\end{equation}\\]Es importante tomar en cuenta cuando el caso en el que hay más ecuaciones lineales que coeficientes \\(\\beta\\); es decir, \\(L\\geq K\\). En estos casos es muy probrable que haya solución, por lo que mejor que se puede estimar es pones la ecuación (3.1), tan pequeña como sea posible. Por lo mismo el paso que nos lleva la ecuación (3.2), debe eliminarse \\(N^{-1}\\). El objetivo:\\[\\begin{equation}\n\\min_{\\beta} \\left[\\sum_{=1}^{N}z_i^{'}x_i\\beta\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_i\\beta\\right]\n\\tag{3.3}\n\\end{equation}\\]Así pues nombramos W como una matriz simétrica de \\(W\\times W\\) donde se genera la variable \\(b\\) que debemos minimizar que sustituye \\(\\beta\\) creando una función cuadrática en la ecuación (3.2).\n\\[\\begin{equation}\n\\min_{b}\\left[\\sum_{=1}^{N}z_i^{'}x_ib\\right]^{-1}\\left[\\sum_{=1}^{N}z_i^{'}y_ib\\right]\n\\tag{3.4}\n\\end{equation}\\]\\[\\begin{equation}\n\\therefore\\hat{\\beta}=[X^{'}Z\\hat{W}Z^{'}X]^{-1}[X^{'}Z\\hat{W}Z^{'}Y]\n\\end{equation}\\]Sin embargo, \\(X^{'}Z\\hat{W}Z^{'}X\\) debe ser singular para que haya una solución. Para esto se asume que \\(\\hat{W}\\) tiene un limite de probabilidad singular. Esto se describe como \\(\\hat{W}\\xrightarrow[]{p}W\\) y \\(N\\xrightarrow[]{}W\\infty\\) donde \\(W\\) es aleatorio, es una matriz positiva definida simétrica de \\(L\\times L\\).","code":""},{"path":"capital-asset-pricing-model-capm.html","id":"capital-asset-pricing-model-capm","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4 CAPITAL ASSET PRICING MODEL (CAPM)","text":"","code":""},{"path":"capital-asset-pricing-model-capm.html","id":"el-problema-3","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.1 El problema","text":"Una vez que hemos establecido la manera en la que se pueden estimar algunos valores –como las regresiones lineales y el método de máxima verosimilitud–, además de la naturaleza de los retornos de algunos activos en el capítulo 4, es posible comenzar hablar de maneras en la que se pueden estimar los valores futuros de los rendimientos de activos y –de esta manera– poder tomar mejores decisiones de inversiones. Por ello, hablaremos del modelo de Capital Asset Pricing Model. El modelo es muy sencillo y pretende estimar su rentabilidad esperada en función del riesgo sistemático. Por lo mismo, en este modelo se utilizan los valores de los precios de los activos lo largo del tiempo y utiliza la intuición con la que derivamos la ecuación lineal con los Mínimos cuadrados ordinarios (MCO).En la ecuación (4.1)\\(R_{jt}\\) es el retorno del portafolio \\(j\\) en el tiempo \\(t\\)\\(R_{jt}\\) es el retorno del portafolio \\(j\\) en el tiempo \\(t\\)\\(R_{ft}\\) es el retorno de un bono sin riesgo gubernamental en un año. Parecido los CETES.\\(R_{ft}\\) es el retorno de un bono sin riesgo gubernamental en un año. Parecido los CETES.\\(R_{mt}\\) es el retorno en un portafolio de mercado.\\(R_{mt}\\) es el retorno en un portafolio de mercado.\\(u_{jt}\\) es el retorno en un portafolio de mercado.\\(u_{jt}\\) es el retorno en un portafolio de mercado.\\(\\alpha_{j},\\beta_j\\) son los coeficientes que queremos obtener.\\(\\alpha_{j},\\beta_j\\) son los coeficientes que queremos obtener.De esta manera, \\(\\alpha_j\\) es el coeficiente que más nos interesa debido que queremos ver si el activo supera o el index del mercado con base en el activo fijo.Si \\(\\alpha_j\\) es positivo entonces sabemos que el retorno tiene buenos rendimiendtos y uno negativo significa que . Por tanto \\(H_0:\\alpha_j=0\\)","code":""},{"path":"capital-asset-pricing-model-capm.html","id":"estimación-r-1","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.2 Estimación R","text":"Para la estimación utilizaremos el paquete “BatchGetSymbols”. Este paquete nos permitirá descargar información acerca de la bolsa de valores internacional.","code":""},{"path":"capital-asset-pricing-model-capm.html","id":"estimación","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.3 ESTIMACIÓN","text":"","code":""},{"path":"capital-asset-pricing-model-capm.html","id":"dependencias-1","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.3.1 Dependencias","text":"","code":"\n#install.packages(\"pacman\")\n#pacman nos permite cargar varias librerias en una sola línea\nlibrary(pacman)\npacman::p_load(tidyverse,BatchGetSymbols,ggplot2,lubridate,readxl,tidyquant)"},{"path":"capital-asset-pricing-model-capm.html","id":"descarga-de-los-valores-1","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.3.2 Descarga de los valores","text":"\nFigure 4.1: Relación de excesos de retornos entre AMZN y SP500\n\nFigure 4.2: Relación de excesos de retornos entre TSLA y SP500\nDe esta manera sabemos que el rendimiento de TSLA es mayor debido que el coeficiente \\(\\alpha=-2.9534\\), lo cual indica peores rendimientos al resto del SP500.","code":"\n#Primero determinamos el lapso de tiempo\npd<-as.Date(\"2021/09/18\") #primer fecha\npd\n#> [1] \"2021-09-18\"\nld<-as.Date(\"2022/09/18\") #última fecha\nld\n#> [1] \"2022-09-18\"\n#Intervalos de tiempo\nint<-\"monthly\"\n#Datos a elegir\ndt<-c(\"AMZN\")\ndt2<-c(\"TSLA\")\n#Descargando los valores\n?BatchGetSymbols()\ndata1<- BatchGetSymbols(tickers = dt,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\ndata2<- BatchGetSymbols(tickers = dt2,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n\n#Generando data frame con los valores\ndata_precio_amzn<-data1$df.tickers\ncolnames(data_precio_amzn)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\"\ndata_precio_tls<-data2$df.tickers\ncolnames(data_precio_tls)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\"\n#necesitamos convertir la serie de tiempo de precios en retornos continuos compuestos de los precios de apertura\ndata_precio_amzn$ccrAMZN<-c(NA ,100*diff(log(data_precio_amzn$price.open)))#agregamos un valor NA al principio\ndata_precio_amzn$ccrAMZN#estos son los retornos\n#>  [1]          NA  -3.2011678   2.1889913   5.3061639\n#>  [5]  -5.6279333 -11.0646538   1.8052718   7.2089622\n#>  [9] -29.3475086  -0.1185366 -13.9945965  23.8807273\n#> [13]  -6.8696583\n\ndata_precio_tls$ccrTSLA<-c(NA ,100*diff(log(data_precio_tls$price.open)))#agregamos un valor NA al principio\ndata_precio_tls$ccrTSLA\n#>  [1]         NA   5.796888  38.591933   1.361865  -1.121972\n#>  [6] -20.478772  -7.264574  21.765521 -22.795320 -13.089771\n#> [11] -10.336735  28.307900 -10.009692\n#formateando por año y mes\ndata_precio_tls$ref.date=format(as.Date(data_precio_tls$ref.date), \"%m/%Y\")\ndata_precio_amzn$ref.date=format(as.Date(data_precio_amzn$ref.date), \"%m/%Y\")\n#Compararemos con los CETES\nCETES_sep2021_2022<-read_excel(\"BD/CETES-sep2021-2022.xlsx\", skip=17)\nhead(CETES_sep2021_2022)\n#> # A tibble: 6 × 2\n#>   Fecha               SF43936\n#>   <dttm>                <dbl>\n#> 1 2021-09-15 00:00:00    4.6 \n#> 2 2021-09-23 00:00:00    4.58\n#> 3 2021-09-30 00:00:00    4.69\n#> 4 2021-10-07 00:00:00    4.81\n#> 5 2021-10-14 00:00:00    4.79\n#> 6 2021-10-21 00:00:00    4.83\n#indice sp500\nSP500 <- read_csv(\"BD/Download Data - INDEX_US_S&P US_SPX.csv\")\nSP500$ccrSP500<-c(NA ,100*diff(log(SP500$Open)))\nnames(SP500)[1]<-paste('ref.date')\n#formateando por año y mes\n\n#cetes\ncete_1_año<-10.10#esto es el rendimiento a un año de un cete gubernamental seguro\n\n#Juntamos el df\nCAPM_2<-merge(data_precio_amzn, data_precio_tls, by = c('ref.date'))\nCAPM_4<-merge(SP500, CAPM_2, by = c('ref.date'))\nCAPM<-data.frame(CAPM_4)\n\n#exceso de retorno\nCAPM$excess_ret_AMZN<-CAPM$ccrAMZN-cete_1_año\nCAPM$excess_ret_SP500<-CAPM$ccrSP500-cete_1_año\nCAPM$excess_ret_TSLA<-CAPM$ccrTSLA-cete_1_año\n#relacion entre los excesos de demanda\nggplot(CAPM, aes(x=excess_ret_AMZN, y=excess_ret_SP500))+geom_point()+labs(title=\"Relación de excesos de retornos entre TSLA y AMZN\",y=\"Exceso de demanda de SP500\", x=\"Exceso de demanda de AMZN\")+theme_light()\n#> Warning: Removed 2 rows containing missing values\n#> (geom_point).\n#relacion entre los excesos de demanda\nggplot(CAPM, aes(x=excess_ret_TSLA, y=excess_ret_SP500))+geom_point()+labs(title=\"Relación de excesos de retornos entre TSLA y AMZN\",y=\"Exceso de demanda de SP500\", x=\"Exceso de demanda de TSLA\")+theme_light()\n#> Warning: Removed 2 rows containing missing values\n#> (geom_point).\n#veamos la regresion lineal\nCAPM_lr<-lm(excess_ret_TSLA~excess_ret_SP500,data = CAPM)\nsummary(CAPM_lr)\n#> \n#> Call:\n#> lm(formula = excess_ret_TSLA ~ excess_ret_SP500, data = CAPM)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -23.980 -13.391  -5.548  11.572  37.067 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)       -3.2334    11.8097  -0.274     0.79\n#> excess_ret_SP500   0.5379     1.0789   0.499     0.63\n#> \n#> Residual standard error: 20.88 on 9 degrees of freedom\n#>   (2 observations deleted due to missingness)\n#> Multiple R-squared:  0.02687,    Adjusted R-squared:  -0.08125 \n#> F-statistic: 0.2486 on 1 and 9 DF,  p-value: 0.6301\nalpha1<-coefficients(CAPM_lr)[1]\nalpha1<0\n#> (Intercept) \n#>        TRUE"},{"path":"capital-asset-pricing-model-capm.html","id":"ejercicio-compara-con-tsla-con-el-apple","chapter":"4 CAPITAL ASSET PRICING MODEL (CAPM)","heading":"4.4 Ejercicio Compara con TSLA con el APPLE","text":"","code":"\ndt3<-\"AAPL\"\ndata3<-BatchGetSymbols(tickers = dt3,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n#> Warning: `BatchGetSymbols()` was deprecated in BatchGetSymbols 2.6.4.\n#> Please use `yfR::yf_get()` instead.\n#> 2022-05-01: Package BatchGetSymbols will soon be replaced by yfR. \n#> More details about the change is available at github <<www.github.com/msperlin/yfR>\n#> You can install yfR by executing:\n#> \n#> remotes::install_github('msperlin/yfR')\n#> \n#> Running BatchGetSymbols for:\n#>    tickers =AAPL\n#>    Downloading data for benchmark ticker\n#> ^GSPC | yahoo (1|1)\n#> AAPL | yahoo (1|1) - Got 100% of valid prices | Well done!\ndata_precio_AAPL<-data3$df.tickers\ncolnames(data_precio_AAPL)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\"\ndata_precio_AAPL$ccrAAPL<-c(NA ,100*diff(log(data_precio_AAPL$price.open)))#agregamos un valor NA al principio\ndata_precio_AAPL$ccrAAPL\n#>  [1]         NA  -1.330092   4.875668  11.698469   5.996413\n#>  [6]  -2.171531  -5.498712   5.510207 -10.483068  -4.442864\n#> [11]  -9.701946  16.851754  -2.751627\ndata_precio_AAPL$ref.date=format(as.Date(data_precio_AAPL$ref.date), \"%m/%Y\")\nCAPM_3<-merge(data_precio_AAPL, CAPM, by = c('ref.date'))\nCAPM_3$excess_ret_AAPL<-CAPM_3$ccrAAPL-cete_1_año\n#veamos la regresion lineal\nCAPM3_lr<-lm(excess_ret_AAPL~excess_ret_SP500,data = CAPM_3)\nsummary(CAPM3_lr)\n#> \n#> Call:\n#> lm(formula = excess_ret_AAPL ~ excess_ret_SP500, data = CAPM_3)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -10.9038  -5.4365   0.4641   3.4629  14.1798 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)       -4.7542     4.9105  -0.968    0.358\n#> excess_ret_SP500   0.4663     0.4486   1.039    0.326\n#> \n#> Residual standard error: 8.682 on 9 degrees of freedom\n#>   (2 observations deleted due to missingness)\n#> Multiple R-squared:  0.1072, Adjusted R-squared:  0.007964 \n#> F-statistic:  1.08 on 1 and 9 DF,  p-value: 0.3258\nalpha2<-coefficients(CAPM3_lr)[1]\nalpha2<0\n#> (Intercept) \n#>        TRUE"},{"path":"estacionariedad.html","id":"estacionariedad","chapter":"5 Estacionariedad","heading":"5 Estacionariedad","text":"","code":""},{"path":"estacionariedad.html","id":"el-problema-4","chapter":"5 Estacionariedad","heading":"5.1 El problema","text":"Los fundamentos de las series de tiempo están basados en la\nestacionalidad. Una serie de tiempo \\({r_t}\\) que estudia los retornos de\nun activo lo largo de tiempo es estrictamente estacionaria si la\ndistribución conjunta de los retornos \\((r_{t1},\\dots,r_{t1})\\) es\nexactamente idéntica en \\((r_{t1+T},\\dots,r_{t1+T})\\), es decir cuando\npasa \\(T\\) años, por ejemplo. En otras palabras, definiremos una serie\nde tiempo como un vector de variables \\({X_t}\\) aleatorias de dimensión\n\\(T\\), dado como:\\[\\begin{equation}\n    X_1, X_2, X_3, \\ldots ,X_T\n\\end{equation}\\]Es decir, definiremos una serie de tiempo como una\nrealización de un proceso estocástico –o un Proceso Generador de Datos\n(PGD). Consideremos una muestra de los múltiples posibles resultados de\nmuestras de tamaño \\(T\\), la colección dada por:\\[\\begin{equation}\n    \\{X^{(1)}_1, X^{(1)}_2, \\ldots, X^{(1)}_T\\}\n    \\tag{5.1}\n\\end{equation}\\]Eventualmente podríamos estar dispuestos observar este proceso\nindefinidamente, de forma tal que estemos interesados en observar la\nsecuencia dada por \\(\\{ X^{(1)}_t \\}^{\\infty}_{t = 1}\\), lo cual \ndejaría se ser sólo una de las tantas realizaciones o secuencias del\nproceso estocástico original de la ecuación (5.1).Por lo mismo, cada cambio que se hace al vector \\(\\{ X^{(1)}_t \\}\\) es\nparte del mismo proceso estocástico, por lo que la serie de tiempo es:El proceso estocástico de dimensión \\(T\\) puede ser completamente descrito\npor su función de distribución multivariada de dimensión \\(T\\). \nobstante, sólo nos enfocaremos en sus primer y segundo momentos, es\ndecir, en sus medias o valores esperados \\(\\mathbb{E} (X_t)\\)Para \\(t = 1, 2, \\ldots, T\\):De sus variazas:\\[\\begin{equation*}\n    Var[X_t] = \\mathbb{E}[(X_t - \\mathbb{E}[X_t])^2]\n\\end{equation*}\\] Para \\(t = 1, 2, \\ldots, T\\), y de sus \\(T(T-1)/2\\)\ncovarianzas: \\[\\begin{equation*}\n    Cov[X_t,X_s] = \\mathbb{E}[(X_t - \\mathbb{E}[X_t])(X_s - \\mathbb{E}[X_s])]\n\\end{equation*}\\]Para \\(t < s\\). Por lo tanto, en la forma matricial podemos escribir lo siguiente:\n\\[\\begin{equation*}\n\\left[\n    \\begin{array}{c c c c}\n    Var[X_1] & Cov[X_1,X_2] & \\cdots & Cov[X_1,X_T] \\\\\n    Cov[X_2,X_1] & Var[X_2] & \\cdots & Cov[X_2,X_T] \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    Cov[X_T,X_1] & Cov[X_T,X_2] & \\cdots & Var[X_T] \\\\\n    \\end{array}\n\\right]\n\\end{equation*}\\]\\[\\begin{equation}\n= \\left[\n    \\begin{array}{c c c c}\n    \\sigma_1^2 & \\rho_{12} & \\cdots & \\rho_{1T} \\\\\n    \\rho_{21} & \\sigma_2^2 & \\cdots & \\rho_{2T} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    \\rho_{T1} & \\rho_{T2} & \\cdots & \\sigma_T^2 \\\\\n    \\end{array}\n\\right]\n\\tag{5.2}\n\\end{equation}\\]Donde es claro que en la matriz de la ecuación (5.2) existen \\(T(T-1)/2\\) covarianzas distintas, ya que se cumple que \\(Cov[X_t,X_s] = Cov[X_s,X_t]\\), para \\(t \\neq s\\). menudo, esas covarianzas son denominadas como autocovarianzas puesto que ellas son covarianzas entre variables aleatorias pertenecientes al mismo proceso estocástico pero en un momento \\(t\\) diferente. Si el proceso estocástico tiene una distribución normal multivariada, su función de distribución estará totalmente descrita por sus momentos de primer y segundo orden.","code":""},{"path":"estacionariedad.html","id":"ergocidad","chapter":"5 Estacionariedad","heading":"5.1.1 Ergocidad","text":"Esto implica que los momentos muestrales, los cuales son calculados en la base de una serie de tiempo con un número finito de observaciones, conforme el tiempo \\(T \\rightarrow \\infty\\) sus correspondientes momentos muestrales, tienden los verdaderos valores poblacionales, los cuales definiremos como \\(\\mu\\), para la media, y \\(\\sigma^2_X\\) para la varianza. En pocas palabras, conforme los momentos muestrales aumenten tanto que tiendan al infinito, entonces nos acercamos valores poblacionales de la media y la varianza.\nEste concepto sólo es cierto si asumimos que\\[\\begin{eqnarray*}\n    \\mathbb{E}[X_t] = \\mu_t = \\mu \\\\\n    Var[X_t] = \\sigma^2_X\n\\end{eqnarray*}\\]\nMás formalmente, se dice que el PGD o el proceso estocástico es ergódico en la media si:\n\\[\\begin{equation}\n    \\displaystyle\\lim_{T \\\\infty}{\\mathbb{E} \\left[ \\left( \\frac{1}{T} \\sum^{T}_{t = 1} (X_t - \\mu) \\right) ^2 \\right]} = 0\n\\end{equation}\\]y ergódico en la varianza si:\n\\[\\begin{equation}\n    \\displaystyle\\lim_{T \\\\infty}{\\mathbb{E} \\left[ \\left( \\frac{1}{T} \\sum^{T}_{t = 1} (X_t - \\mu) ^2 - \\sigma^2_X \\right) ^2 \\right]} = 0\n\\end{equation}\\]\n+\nEstas condiciones se les conoce como propiedades de consistencia para las variables aleatorias. Sin embargo, éstas pueden ser probadas. Por ello se les denomina como un supuesto que pueden cumplir algunas de las series. Más importante aún: un proceso estocástico que tiende estar en equilibrio estadístico en un orden ergódico, es estacionario.","code":""},{"path":"estacionariedad.html","id":"tipos-de-estacionariedad","chapter":"5 Estacionariedad","heading":"5.1.2 Tipos de Estacionariedad","text":"Definiremos la estacionariedad por sus momentos del correspondiente proceso estocástico dado por \\(\\{X_t\\}\\):Estacionariedad en media: Un proceso estocástico es estacionario en media si \\(E[X_t] = \\mu_t = \\mu\\) es constante para todo \\(t\\).Estacionariedad en media: Un proceso estocástico es estacionario en media si \\(E[X_t] = \\mu_t = \\mu\\) es constante para todo \\(t\\).Estacionariedad en varianza: Un proceso estocástico es estacionario en varianza si \\(Var[X_t] = \\mathbb{E}[(X_t - \\mu_t)^2] = \\sigma^2_X = \\gamma(0)\\) es constante y finita para todo \\(t\\).Estacionariedad en varianza: Un proceso estocástico es estacionario en varianza si \\(Var[X_t] = \\mathbb{E}[(X_t - \\mu_t)^2] = \\sigma^2_X = \\gamma(0)\\) es constante y finita para todo \\(t\\).Estacionariedad en covarianza: Un proceso estocástico es estacionario en covarianza si \\(Cov[X_t,X_s] = \\mathbb{E}[(X_t - \\mu_t)(X_s - \\mu_s)] = \\gamma(|s-t|)\\) es sólo una función del tiempo y de la distancia entre las dos variables aleatorias. Por lo que depende del tiempo denotado por \\(t\\) (depende de la información contemporánea).Estacionariedad en covarianza: Un proceso estocástico es estacionario en covarianza si \\(Cov[X_t,X_s] = \\mathbb{E}[(X_t - \\mu_t)(X_s - \\mu_s)] = \\gamma(|s-t|)\\) es sólo una función del tiempo y de la distancia entre las dos variables aleatorias. Por lo que depende del tiempo denotado por \\(t\\) (depende de la información contemporánea).Estacionariedad débil: Como la estacionariedad en varianza resulta de forma inmediata de la estacionariedad en covarianza cuando se asume que \\(s = t\\), un proceso estocástico es débilmente estacionario cuando es estacionario en media y covarianza. ESTE ES EL MÁS COMÚN Y POSIBLE, por lo que es el que estudiaremos.Estacionariedad débil: Como la estacionariedad en varianza resulta de forma inmediata de la estacionariedad en covarianza cuando se asume que \\(s = t\\), un proceso estocástico es débilmente estacionario cuando es estacionario en media y covarianza. ESTE ES EL MÁS COMÚN Y POSIBLE, por lo que es el que estudiaremos.","code":""},{"path":"estacionariedad.html","id":"función-de-autocorrelación-acf","chapter":"5 Estacionariedad","heading":"5.1.3 Función de Autocorrelación (ACF)","text":"Para ampliar la discusión, es posible calcular la fuerza o intensidad de la dependencia de las variables aleatorias dentro de un proceso estocástico, ello mediante el uso de las autocovarianzas. Cuando las covarianzas son normalizadas respecto de la varianza, el resultado es un término que es independiente de las unidad de medida aplicada, y se conoce como la función de autocorrelación.Por su parte, un estimador consistente de la función de autocorrelación estará dado por:\n\\[\\begin{equation}\n    \\hat{\\rho}(\\tau) = \\frac{\\sum^{T - \\tau}_{t=1} (X_t - \\hat{\\mu})(X_{t+\\tau} - \\hat{\\mu})}{\\sum^T_{t=1} (X_t - \\hat{\\mu})^2} = \\frac{\\hat{\\gamma}(\\tau)}{\\hat{\\gamma}(0)} \\mbox{, para } \\tau = 1, 2, \\ldots, T-1\n    \\tag{5.3}\n\\end{equation}\\]El estimador de la ecuación (5.3) es asintóticamente insesgado y es relevante puesto que nos dice si una serie de tiempo con estacionariedad débil esta serialmente correlacionada si y solo si \\(\\hat{\\rho}(\\tau)\\neq0\\).","code":""},{"path":"estacionariedad.html","id":"ruido-blanco","chapter":"5 Estacionariedad","heading":"5.1.4 Ruido Blanco","text":"Supongamos una serie de tiempo denotada por: \\(\\{U_t\\}^T_{t = 0}\\). Decimos que el proceso estocástico \\(\\{U_t\\}\\) es un proceso estocástico puramente aleatorio o es un proceso estocástico de ruido blanco o caminata aleatoria, si éste tiene las siguientes propiedades:\\(\\mathbb{E}[U_t] = 0\\), \\(\\forall t\\)\\(\\mathbb{E}[U_t] = 0\\), \\(\\forall t\\)\\(Var[U_t] = \\mathbb{E}[(U_t - \\mu_t)^2] = \\mathbb{E}[(U_t - \\mu)^2] = \\mathbb{E}[(U_t)^2] = \\sigma^2\\), \\(\\forall t\\)\\(Var[U_t] = \\mathbb{E}[(U_t - \\mu_t)^2] = \\mathbb{E}[(U_t - \\mu)^2] = \\mathbb{E}[(U_t)^2] = \\sigma^2\\), \\(\\forall t\\)\\(Cov[U_t,U_s] = \\mathbb{E}[(U_t - \\mu_t)(U_s - \\mu_s)] = \\mathbb{E}[(U_t - \\mu)(U_s - \\mu)] = \\mathbb{E}[U_t U_s] = 0\\), \\(\\forall t \\neq s\\).\\(Cov[U_t,U_s] = \\mathbb{E}[(U_t - \\mu_t)(U_s - \\mu_s)] = \\mathbb{E}[(U_t - \\mu)(U_s - \\mu)] = \\mathbb{E}[U_t U_s] = 0\\), \\(\\forall t \\neq s\\).\\(\\hat{\\rho}(\\tau)=0\\)\\(\\hat{\\rho}(\\tau)=0\\)En palabras. Un proceso \\(U_t\\) es un ruido blanco si su valor promedio es cero (0), tiene una varianza finita y constante, y además le importa la historia pasada, así su valor presente se ve influenciado por sus valores pasados importando respecto de que periodo se tome referencia.Para procesos estacionarios, dicha función de autocorrelación esta dada por:\n\\[\\begin{equation}\n    \\rho(\\tau) = \\frac{\\mathbb{E}[(X_t - \\mu)(X_{t+\\tau} - \\mu)]}{\\mathbb{E}[(X_t - \\mu)^2]} = \\frac{\\gamma(\\tau)}{\\gamma(0)}\n\\end{equation}\\]","code":""},{"path":"estacionariedad.html","id":"estimación-1","chapter":"5 Estacionariedad","heading":"5.2 Estimación","text":"","code":""},{"path":"estacionariedad.html","id":"dependencias-2","chapter":"5 Estacionariedad","heading":"5.2.1 Dependencias","text":"","code":"\n#install.packages(\"pacman\")\n#pacman nos permite cargar varias librerias en una sola línea\nlibrary(pacman)\npacman::p_load(tidyverse,BatchGetSymbols,ggplot2,lubridate,readxl,forecast,stats)"},{"path":"estacionariedad.html","id":"caminata","chapter":"5 Estacionariedad","heading":"5.3 Caminata","text":"\nFigure 5.1: Ejemplo de 10 trayectorias de la caminata aleatoria, cuando sólo es posible cambios de +1 y -1\nAsí, el proceso estocástico dado por la caminata alaeatoria sin un\ntérmino de ajuste es estacionario en media, pero en varianza o en\ncovarianza, y consecuentemente, en general estacionario, condición\nque contraria al caso del proceso simple descrito en \\(U_t\\).Es facil ver que muchas de las posibilidades de realización de este\nproceso estocástico (series de tiempo) pueden tomar cualquiera de las\nrutas consideradas en el Figura 5.1. Ahora analicemos\nun solo camino.","code":"\n\nset.seed(1234)\n# Utilizaremos una función guardada en un archivo a parte\n# Llamamos a la función:\nsource(\"funciones/Caminata.R\")\n\n# Definimos argumentos de la función\nOpciones <- c(-1, 1)\n#\nSoporte <- 10000\n\n# Vamos a réplicar el proceso con estos parámetros\nRango <- 200\n#\nCaminos <- 10\n\n#\n\nfor(i in 1:Caminos){\n  TT <- data.matrix(data.frame(Caminata(Opciones, Soporte)[1]))\n  #\n  G_t <- data.matrix(data.frame(Caminata(Opciones, Soporte)[2]))\n  #\n  plot(TT, G_t, col = \"blue\", type = \"l\", ylab = \"Ganancias\", xlab = \"Tiempo\", ylim = c(-Rango,Rango))\n  #\n  par(new = TRUE)\n  #\n  i <- i +1\n}\n#\npar(new = FALSE)"},{"path":"estacionariedad.html","id":"un-camino","chapter":"5 Estacionariedad","heading":"5.4 Un camino","text":"\nFigure 5.2: Una Caminata aleatoria cuando sólo es posible cambios de +1 y -1\nHay que convertirlo serie de tiempo","code":"\n#Generamos datos\n  TT1 <- data.matrix(data.frame(Caminata(Opciones, Soporte)[1]))\n  G_t1 <- data.matrix(data.frame(Caminata(Opciones, Soporte)[2]))\n#Creemos un data frame\n  dt_caminata<-data.frame(TT1,G_t1)\n  colnames(dt_caminata)<-c(\"t\",\"ganancias\")\n  head(dt_caminata)\n#>   t ganancias\n#> 1 1        -1\n#> 2 2        -2\n#> 3 3        -1\n#> 4 4        -2\n#> 5 5        -3\n#> 6 6        -4\n#plot\n  plot(TT1, G_t1, col = \"blue\", type = \"l\", ylab = \"Ganancias\", xlab = \"Tiempo\", ylim = c(-Rango,Rango))\n#serie de tiempo\ncaminata_ts<-ts(G_t1,start=1,end=Soporte)"},{"path":"estacionariedad.html","id":"estacionariedad-caminata","chapter":"5 Estacionariedad","heading":"5.4.1 Estacionariedad Caminata","text":"\nFigure 5.3: Función de Autocorrelación de una Caminata\nComo se comentó con anterioridad en la Figura 5.3 es\nevidente que la Caminata si tiene autocorrelacion, por lo que nuestro\nplot de autocorrelacion tiene valores muy altos en todos los lags.\nVeamos los lags.\nFigure 5.4: Lags de una sola caminata\nDe nuevo, esto al ser creado de manera estandarizada estamos seguros de\nque va ser estacionario en la medio, por lo mismo los lags de la\nFigura 5.4 se ven tan correlacionados.","code":"\nACF_caminata_ts<-acf(caminata_ts,na.action = na.pass, main = \"Función de Autocorrelación de una Caminata\")\ngglagplot(caminata_ts,lags=10,do.lines=FALSE,colour=FALSE)+theme_light()"},{"path":"estacionariedad.html","id":"precios-de-un-activo","chapter":"5 Estacionariedad","heading":"5.5 Precios de un activo","text":"Veamos la serie de tiempo\nFigure 5.5: Serie de tiempo de los retornos de año en los últimos 20 años\n","code":"\n#Primero determinamos el lapso de tiempo\npd<-Sys.Date()-(365*20) #primer fecha\npd\n#> [1] \"2002-10-03\"\nld<-Sys.Date() #última fecha\nld\n#> [1] \"2022-09-28\"\n#Intervalos de tiempo\nint<-\"monthly\"\n#Datos a elegir\ndt<-c(\"AMZN\")\ndt2<-c(\"TSLA\")\n#Descargando los valores\ndata1<- BatchGetSymbols(tickers = dt,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n#Generando data frame con los valores\ndata_precio_amzn<-data1$df.tickers\ncolnames(data_precio_amzn)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\"\n\n#necesitamos convertir la serie de tiempo de precios en retornos continuos compuestos de los precios de apertura\ndata_precio_amzn$ccrAMZN<-c(NA ,100*diff(log(data_precio_amzn$price.open)))#agregamos un valor NA al principio\ndata_precio_amzn$ccrAMZN#estos son los retornos\n#>   [1]           NA  13.51679325  22.83329766 -22.98950701\n#>   [5]  13.39221448   0.95260416  14.27998202  11.55626991\n#>   [9]  24.11122449  -0.46684144  13.08785513  11.63599301\n#>  [13]   3.89974592  12.48104071  -0.73260401  -3.06108260\n#>  [17]  -4.08140972 -16.32741069   0.99457279   0.06902105\n#>  [21]   9.61879412  11.67844638 -33.59147712  -0.57381482\n#>  [25]   7.69997922 -18.78100714  15.60691856  11.66713068\n#>  [29]  -4.43506452 -20.41392362  -1.23405211  -6.96531282\n#>  [33]   9.64353557  -6.77486160  30.02382912  -5.40177077\n#>  [37]   6.39945115 -12.58398922  20.12391421  -2.92703823\n#>  [41]  -7.77281354 -15.93630872  -2.10477279  -4.11970307\n#>  [45]  -1.60415929  10.64572285 -37.21478392  15.01070027\n#>  [49]   3.59739571  17.58906665   5.43570463  -4.00357496\n#>  [53]  -1.90531667   3.54637914   1.33891100  42.77167396\n#>  [57]  11.98170332  -0.13070948  12.66409736   2.27857959\n#>  [61]  15.63296023  -6.26135927   2.56510858   5.74113839\n#>  [65] -18.78533471 -21.72447597  13.78662202   7.15014819\n#>  [69]   3.44753666 -11.63053849   5.54650897   8.53074641\n#>  [73] -14.71605773 -24.20236452 -29.39126222  20.09953181\n#>  [77]  13.15576837   8.77225235  13.27882326   9.60320128\n#>  [81]  -2.73678724   7.64068237   2.50334747  -6.96036997\n#>  [85]  13.59745291  24.90536163  14.32806129  -0.50514401\n#>  [89] -10.08447333  -3.70473986  13.45839135   1.02565002\n#>  [93]  -9.33660068 -13.76436786   8.99531736   5.87517724\n#>  [97]  21.76202538   4.58513429   8.56726887   1.22598823\n#> [101]  -6.16865517   1.74979032   4.53458328   7.93222740\n#> [105]  -0.25978671   4.72685785   9.04110889  -4.41608958\n#> [109]   0.80039290  -4.18766494  -8.13529694  -8.68550170\n#> [113]  -1.18960511   3.43828044   9.60224827  14.70991690\n#> [117]  -9.58159747   9.53799598   2.08880372   5.85976366\n#> [121]   2.83140800  -8.65274050   7.52661134   1.39202437\n#> [125]   4.89612270  -2.12710012   1.39936277  -5.02332605\n#> [129]   5.76221809   3.66491122   8.27850152  -6.24554343\n#> [133]   9.85520147  15.15285156   8.73395739  -0.05013788\n#> [137] -10.51934673  -0.06687288  -5.92858190 -10.58568315\n#> [141]   2.74371861   4.15753522  -3.80625428   8.04816141\n#> [145]  -5.42111518  -5.03065911   9.90317538  -7.85404256\n#> [149]  11.32156221   8.43295383  -2.32429615  13.01462014\n#> [153]   1.54061721   2.05813986  20.15392877  -7.39490376\n#> [157]   2.34828935  20.47843365   7.17052347  -2.62563883\n#> [161] -12.67694180  -3.85435390   5.96629237  11.72089295\n#> [165]   8.23387458  -0.49783030   5.76252931   1.44112456\n#> [169]   8.10699776  -4.52676184  -6.00796092   0.72964776\n#> [173]   8.98955770   2.83447462   4.01536256   4.38443827\n#> [177]   7.35281333  -2.61760725   2.36894617  -1.20285851\n#> [181]  -2.07377928  13.68712240   5.85471090  -0.00427124\n#> [185]  20.93976645   4.63815978  -6.55115525   9.77684681\n#> [189]   4.61358018   2.75160333   5.84583306  12.74521370\n#> [193]  -0.22279328 -21.94794383   8.60716489 -18.86826361\n#> [197]  11.20213025   0.98664739   8.39682297   7.12720047\n#> [201]  -9.38002536   8.85565506  -2.70183034  -5.58782369\n#> [205]  -1.36520548   2.37757442   0.91249016   3.83805218\n#> [209]   6.98245156  -5.31693095   1.37938043  18.97247680\n#> [213]   4.64889431  11.92308161  14.25393454   9.27398656\n#> [217]  -8.41337555  -4.66642316   4.05671846   2.52393793\n#> [221]  -0.84885499  -3.59427728  -0.31861156  11.12179968\n#> [225]  -7.17375312   5.72503641  -2.40180912   4.18486227\n#> [229]  -6.11473001   2.18899134   5.30616390  -5.62793333\n#> [233] -11.06465380   1.80527180   7.20896224 -29.34750864\n#> [237]  -0.11853658 -13.99459654  23.88072732  -6.86965832\n#tenemos 20 retornos a lo largo de 20 años\nret_20_amazn<-ggplot(data=data_precio_amzn, aes(x=ref.date))+geom_line(aes(y=ccrAMZN))+labs(title=\"Retornos de AMZN en los últimos 20 años\",y=\"Retornos\", x=\"Años\")+theme_light()\nret_20_amazn"},{"path":"estacionariedad.html","id":"serie-de-tiempo","chapter":"5 Estacionariedad","heading":"5.5.1 Serie de tiempo","text":"Primero que nada es importante cargar los datos un objeto series de\ntiempo. Esto nos lo permite la función ts(). Además debemos serciorarnos\nde que los datos esten en orden cronológico.","code":"\ndata_precio_amzn<-data_precio_amzn[order(data_precio_amzn$ref.date),]\nhead(data_precio_amzn)#dado que ya estaba en orden cronológico nuestro df no cambia\n#> # A tibble: 6 × 11\n#>   ticker ref.date     volume price…¹ price…² price…³ price…⁴\n#>   <chr>  <date>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 AMZN   2002-10-03   3.72e9   0.840    1.01   0.818   0.968\n#> 2 AMZN   2002-11-01   4.13e9   0.961    1.23   0.91    1.17 \n#> 3 AMZN   2002-12-02   3.11e9   1.21     1.25   0.922   0.944\n#> 4 AMZN   2003-01-02   3.38e9   0.960    1.16   0.928   1.09 \n#> 5 AMZN   2003-02-03   2.32e9   1.10     1.12   0.980   1.10 \n#> 6 AMZN   2003-03-03   3.28e9   1.11     1.40   1.07    1.30 \n#> # … with 4 more variables: price.adjusted <dbl>,\n#> #   ret.adjusted.prices <dbl>, ret.closing.prices <dbl>,\n#> #   ccrAMZN <dbl>, and abbreviated variable names\n#> #   ¹​price.open, ²​price.high, ³​price.low, ⁴​price.close\n#hagamos el objeto ts\nret_amazn_ts<-ts(data_precio_amzn$ccrAMZN)\nplot(ret_amazn_ts)#de esta manera podemos ver que se cargo bien debido a que es igual al ggplot"},{"path":"estacionariedad.html","id":"estacionariedad-1","chapter":"5 Estacionariedad","heading":"5.5.2 Estacionariedad","text":"\nFigure 5.6: Lag Plot que nos muestra la correlación entre 20 lags\n\nFigure 5.7: Función de Autocorrelación de los retornos de AMZN en los ultimos 20 años\nLa Figura 5.6 nos idica la manera en la que se\ncorrelacionan los lags, evidentemente se puede ver ningún tipo de\ncorrelacioo1ón visible. Similarmente la Figura 5.7 en\ndonde se muestra la función de autocorrelación. Expecto al primer lag\n–que muestra correlacion debido que se esta comparando consigo\nmismo– es evidente que hay correlacioo1ón fuerte entre ninguno de\nlos lags. Por lo mismo, sería difícil poder encontrar y estimar valores\nfuturos debido que la Figura 5.6 y la Figura\n5.7 indican que la serie de tiempo de los retornos de\nAMZN de la Figura 5.5 es completamente aleatorio y \nhay estacionariedad.","code":"\n#MA_m5<-forecast::ma(ret_amazn_ts,order=11,centre=TRUE)\n#plot(ret_amazn_ts)+lines(MA_m5, col=\"red\", lwd=2)\ngglagplot(ret_amazn_ts,lags=20,do.lines=FALSE,colour=FALSE)+theme_light()\nACF_ret_amazn_ts<-acf(ret_amazn_ts,na.action = na.pass)"},{"path":"procesos-estacionarios-univariados.html","id":"procesos-estacionarios-univariados","chapter":"6 Procesos estacionarios univariados","heading":"6 Procesos estacionarios univariados","text":"En este capítulo analizaremos el método o metodología de análisis de\nseries de tiempo propuesto por Box y Jenkins (1970). Los modelos\npropuestos dentro de está metodología o conjunto de métodos se han\nvuelto indispensables para efectos de realizar pronósticos de corto\nplazo.En este sentido, se analizarán los métodos más importantes en series de\ntiempo: Autoregresivos (AR) y de Medias Móviles (MA). Asimismo, se\nrealizará un análisis de los procesos que resultan de la combinación de\nambos, conocida como ARMA, los cuales son más comúnmente usados para\nrealizar pronósticos.","code":""},{"path":"procesos-estacionarios-univariados.html","id":"procesos-autoregresivos-ar","chapter":"6 Procesos estacionarios univariados","heading":"6.1 Procesos Autoregresivos (AR)","text":"Los procesos autoregresivos tienen su origen en el trabajo de Cochrane y\nOrcutt de 1949, mediante el cual analizaron los residuales de una\nregresión clásica como un proceso autoregresivo. Puede consultarse el\napéndice para la discusión del modelo de regresión clásica.","code":""},{"path":"procesos-estacionarios-univariados.html","id":"ar1","chapter":"6 Procesos estacionarios univariados","heading":"6.1.1 AR(1)","text":"Como primer caso analizaremos al proceso autoregresivo de primer orden,\n\\(AR(1)\\), el cual podemos definir como una Ecuación Lineal en Diferencia\nEstocástica de Primer Orden. Diremos que una Ecuación Lineal en\nDiferencia de Primer Orden es estocástica si en su representación\nanalítica considera un componente estocástico como en la ecuación\n(6.1) descrita continuación:\\[\\begin{equation}\n    X_t = a_0 + a_1 X_{t-1} + U_t\n\\tag{6.1}\n\\end{equation}\\]Donde \\(a_0\\) es un término constante, \\(U_t\\) es un proceso estacionario,\ncon media cero (0), una varianza finita y constante (\\(\\sigma^2\\)) y una\ncovarianza que depende de la distancia entre \\(t\\) y cualquier \\(t-s\\)\n(\\(\\gamma_s\\))–que depende de los valores pasados o futuros de la\nvariable–, \\(X_0\\) es el valor inicial de \\(X_t\\). obstante, en general\nvamos asumir que la covarianza será cero (0), por lo que tendremos un\nproceso puramente aleatorio. Considerando la ecuación (6.1) y\nun proceso de sustitución sucesivo podemos establecer lo siguiente,\nempezando con \\(X_1\\): \\[\\begin{eqnarray*}\n    X_{1} & = & a_0 + a_1 X_{0} + U_{1}\n\\end{eqnarray*}\\]Para \\(X_2\\): \\[\\begin{eqnarray*}\nX_{2} & = & a_0 + a_1 X_{1} + U_{2} \\\\\n    & = & a_0 + a_1 (a_0 + a_1 X_{0} + U_{1}) + U_{2} \\\\\n    & = & a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}\n\\end{eqnarray*}\\]Para \\(X_3\\): \\[\\begin{eqnarray*}\nX_{3} & = & a_0 + \\alpha X_{2} + U_{3} \\\\\n    & = & a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}) + U_{3} \\\\\n    & = & a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 X_{0} + a_1^2 U_{1} + a_1 U_{2} + U_{3}\n\\end{eqnarray*}\\]Así, para cualquier \\(X_t\\), \\(t = 1, 2, 3, \\ldots\\), obtendríamos:\n\\[\\begin{eqnarray}\nX_{t} & = & a_0 + a_1 X_{t - 1} + U_{t} \\nonumber \\\\\n    & = & a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 a_0 + \\ldots + a_1^{t-2} a_0 + a_1^{t-1} X_{0} \\nonumber \\\\\n    &   & + a_1^{t-2} U_{1} + \\ldots + a_1 U_{t - 2} + U_{t - 1}) + U_{t} \\nonumber \\\\\n    & = & a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 a_0 + \\ldots + a_1^{t-1} a_0 + a_1^{t} X_{0} \\nonumber \\\\\n    &   & + a_1^{t-1} U_{1} + \\ldots a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t} \\nonumber \\\\\n    & = & (1 + a_1 + a_1^2 + a_1^3 + \\ldots + a_1^{t-1}) a_0 + a_1^{t} X_{0} \\nonumber \\\\\n    &   & + a_1^{t-1} U_{1} + \\ldots + a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t}  \\nonumber\\\\\n    & = & \\frac{1 - a_1^t}{1 - a_1} a_0 + a_1^{t} X_{0} + \\sum^{t-1}_{j = 0} a_1^{j} U_{t - j}\n    \\tag{6.2}\n\\end{eqnarray}\\]De esta forma en la ecuación (6.2) observamos un proceso que\nes explicado por dos partes: una que depende del tiempo y otra que\ndepende de un proceso estocástico. Asimismo, debe notarse que la\ncondición de convergencia es idéntica que en el caso de ecuaciones en\ndiferencia estudiadas al inicio del curso: \\(\\lvert a_1 \\lvert < 1\\), por\nlo que cuando \\(t \\\\infty\\), la expresión (6.2) será la\nsiguiente:\\[\\begin{equation}\n    X_t = \\frac{1}{1 - a_1} a_0 + \\sum^{\\infty}_{j = 0} a_1^{j} U_{t - j}\n    \\tag{6.3}\n\\end{equation}\\]Así, desaparece la parte dependiente del tiempo y únicamente prevalece\nla parte que es dependiente del proceso estocástico. Esta es la solución\nde largo plazo del proceso \\(AR(1)\\), la cual depende del proceso\nestocástico. Notemos, además, que esta solución implica que la variable\no la serie de tiempo \\(X_t\\) es tambien un proceso estocástico que hereda\nlas propiedades de \\(U_t\\). Así, \\(X_t\\) es también un proceso estocástico\nestacionario, como demostraremos más adelante.Observemos que la ecuación (6.3) se puede reescribir si\nconsideramos la formulación que en la literatura se denomina como la\ndescomposición de Wold, en la cual se define que es posible asumir que\n\\(\\psi_j = a_1^j\\) y se considera el caso en el cual\n\\(\\lvert a_1 \\lvert< 1\\), de esta forma tendremos que por ejemplo cuando:\n\\[\\begin{equation*}\n    \\sum^{\\infty}_{j = 0} \\psi^2_j = \\sum^{\\infty}_{j = 0} a_1^{2j} = \\frac{1}{1 - a_1^2}\n\\end{equation*}\\]Alternativamente y de forma similar las ecuaciones en diferencia\nestudiadas previamente podemos escribir el proceso \\(AR(1)\\) mediante el\nuso del operador rezago como:\\[\\begin{eqnarray}\n    X_t & = & a_0 + a_1 L X_t + U_t \\nonumber \\\\\n    X_t - a_1 L X_t & = & a_0 + U_t \\nonumber \\\\\n    (1 - a_1 L) X_t & = & a_0 + U_t \\nonumber \\\\\n    X_t & = & \\frac{a_0}{1 - a_1 L} + \\frac{1}{1 - a_1 L} U_t\n    \\tag{6.4}\n\\end{eqnarray}\\]En esta última ecuación retomamos el siguiente término para reescribirlo\ncomo:\\[\\begin{equation}\n    \\frac{1}{1 - a_1 L} = 1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \\ldots\n    \\tag{6.5}\n\\end{equation}\\]Tomando este resultado para sustituirlo en ecuación (6.4),\nobtenemos la siguiente expresión:\\[\\begin{eqnarray}\nX_t & = & (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \\ldots) a_0 + (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \\ldots) U_t \\nonumber \\\\\n    & = & (1 + a_1 + a_1^2 + a_1^3 + \\ldots) a_0 + U_t + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \\ldots \\nonumber \\\\\n    & = & \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j U_{t-j}\n    \\tag{6.6}\n\\end{eqnarray}\\]Donde la condición de convergencia y estabilidad del proceso descrito en\nesta ecuación es que \\(\\lvert a_1 \\lvert < 1\\). Por lo que hemos\ndemostrado que mediante el uso del operador de rezago es posible llegar\nal mismo resultado que obtuvimos mediante el procedimiento de\nsustituciones iterativas.La ecuación (6.6) se puede interpretar como sigue. La\nsolución o trayectoria de equilibrio de un AR(1) se divide en dos\npartes. La primera es una constante que depende de los valores de \\(a_0\\)\ny \\(a_1\\). La segunda parte es la suma ponderada de las desviaciones o\nerrores observados y acumulados en el tiempo hasta el momento \\(t\\).Ahora obtendremos los momentos que describen la serie de tiempo cuando\nse trata de un porceso \\(AR(1)\\). Para ello debemos obtener la media, la\nvarianza y las covarianzas de \\(X_t\\). Para los siguientes resultados\ndebemos recordar y tener en mente que si \\(U_t\\) es un proceso puramente\naleatorio, entonces:\\(\\mathbb{E}[U_t] = 0\\) para todo \\(t\\)\\(Var[U_t] = \\sigma^2\\) para todo \\(t\\)\\(Cov[U_t, U_s] = 0\\) para todo \\(t \\neq s\\)Dicho lo anterior y partiendo de la ecuación (6.6), el primer\nmomento o valor esperado de la serie de tiempo será el siguiente:\n\\[\\begin{eqnarray}\n\\mathbb{E}[X_t] & = & \\mathbb{E} \\left[ \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j U_{t-j} \\right] \\nonumber \\\\\n    & = & \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j \\mathbb{E}[U_{t-j}] \\nonumber \\\\\n    & = & \\frac{a_0}{1 - a_1} = \\mu\n    \\tag{6.7}\n\\end{eqnarray}\\]Respecto de la varianza podemos escribir la siguiente expresión partir\nde la ecuación (6.6):\\[\\begin{eqnarray}\nVar[X_t] & = & \\mathbb{E}[(X_t - \\mu)^2] \\nonumber \\\\\n    & = & \\mathbb{E} \\left[ \\left( \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j U_{t-j} - \\frac{a_0}{1 - a_1} \\right)^2 \\right] \\nonumber \\\\\n    & = & \\mathbb{E}[(U_{t} + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \\ldots)^2] \\nonumber \\\\\n    & = & \\mathbb{E}[U^2_{t} + a_1^2 U^2_{t-1} + a_1^4 U^2_{t-2} + a_1^6 U^2_{t-3} + \\ldots \\nonumber \\\\\n    &   & + 2 a_1 U_t U_{t-1} + 2 a_1^2 U_t U_{t-2} + \\ldots] \\nonumber \\\\\n    & = & \\mathbb{E}[U^2_{t}] + a_1^2 \\mathbb{E}[U^2_{t-1}] + a_1^4 \\mathbb{E}[U^2_{t-2}] + a_1^6 \\mathbb{E}[U^2_{t-3}] + \\ldots \\nonumber \\\\\n    & = & \\sigma^2 + a_1^2 \\sigma^2 + a_1^4 \\sigma^2 + a_1^6 \\sigma^2 + \\ldots \\nonumber \\\\\n    & = & \\sigma^2 (1 + a_1^2 + a_1^4 + a_1^6 + \\ldots) \\nonumber \\\\\n    & = & \\sigma^2 \\frac{1}{1 - a_1^2} = \\gamma(0)\n    \\tag{6.8}\n\\end{eqnarray}\\]Previo analizar la covarianza de la serie recordemos que para el\nproceso puramente aleatorio \\(U_t\\) su varianza y covarianza puede verse\ncomo \\(\\mathbb{E}[U_t, U_s] = \\sigma^2\\), para \\(t = s\\), y\n\\(\\mathbb{E}[U_t, U_s] = 0\\), para cualquier otro caso, respectivamente.Dicho lo anterior, partiendo de la ecuación (6.6) la\ncovarianza de la serie estará dada por:\\[\\begin{eqnarray}\nCov(X_t, X_{t-\\tau}) & = & \\mathbb{E}[(X_t - \\mu)(X_{t-\\tau} - \\mu)] \\nonumber \\\\\n    & = & \\mathbb{E} \\left[ \\left( \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j U_{t-j} - \\frac{a_0}{1 - a_1} \\right) \\right. \\nonumber \\\\\n    &   & \\left. \\times \\left( \\frac{a_0}{1 - a_1} + \\sum^{\\infty}_{j = 0} a_1^j U_{t-\\tau-j} - \\frac{a_0}{1 - a_1} \\right) \\right] \\nonumber \\\\\n    & = & a_1^{\\tau} \\mathbb{E}[U^2_{t-\\tau} + a_1 U^2_{t-\\tau-1} + a_1^2 U^2_{t-\\tau-2} + a_1^3 U^2_{t-\\tau-3} + \\ldots] \\nonumber \\\\\n    & = & a_1^{\\tau} \\sigma^2 \\frac{1}{1 - a_1^2} = \\gamma(\\tau)\n    \\tag{6.9}\n\\end{eqnarray}\\]Notése que con estos resultados en las ecuaciones (6.8) y\n(6.9) podemos construir la función de autocorrelación teórica\ncomo sigue:\\[\\begin{eqnarray}\n\\rho(\\tau) & = & \\frac{\\gamma(\\tau)}{\\gamma(0)} \\nonumber \\\\\n    & = & a_1^\\tau\n    \\tag{6.10}\n\\end{eqnarray}\\]Donde \\(\\tau = 1, 2, 3, \\ldots\\) y \\(\\lvert a_1 \\lvert < 1\\). Este último\nresultado significa que cuando el proceso autoregresivo es de orden 1\n(es decir, AR(1)) la función de autocorrelación teóricamente es igual al\nparámetro \\(a_1\\) elevado al número de rezagos considerados. obstante,\nnote que esto significa que la autocorrelación observada sea como lo\nexpresa en planteamiento anterior. Por el contrario, una observación\nsencilla mostraría que la autocorrelación observada sería ligeramente\ndistinta la autocorrelación teórica.Ahora veámos algunos ejemplos. En el primer ejemplo simularemos una\nserie y mostraremos el analísis de un proceso construído considerando un\nproceso puramente aleatorio como componente \\(U_t\\).1\nPor su parte, en un segundo ejemplo aplicaremos el análisis una serie\nde tiempo de una variable económica observada.2Para el primer ejemplo consideremos un proceso dado por la forma de un\n\\(AR(1)\\) como en la ecuación (6.4) cuya solución esta dada por la\necuación (6.6). En especifico, supongamos que el término o\ncomponente estocástico \\(U_t\\) es una serie generada partir de numeros\naleatorios de una función normal con media \\(0\\) y desviación estándar\n\\(4\\). Los detalles del proceso simulado se muestra en las siguientes\ngráficas.","code":""},{"path":"procesos-estacionarios-univariados.html","id":"ejemplo-ar1","chapter":"6 Procesos estacionarios univariados","heading":"6.1.1.1 EJEMPLO AR(1)","text":"Por lo tanto tenemos la serie de tiempo \\(AR(1)\\):\n\\[ X_t= 5+0.9X_{t-1}+U_t\\]En este caso el termino estocastico tiene una media de \\(0\\) y una\ndesviación estándar constante \\(\\sigma^2=4\\)\nFigure 6.1: AR(1) considerando \\(X_t=5+0.9X_{t-1}+U_t\\) ; \\(X_0=50\\) y que \\(U_t\\)~\\(N(0, 4)\\) y que \\(U_t \\sim \\mathcal{N}(0, 4)\\)\n\nFigure 6.2: \\(X_t = \\frac{5}{1 - 0.9} + \\sum_{j = 0}^{t-1} 0.9^j U_{t-j}\\), y que \\(U_t \\sim \\mathcal{N}(0, 4)\\)}\n\nFigure 6.3: Función de autocorrelación de un AR(1): \\(\\rho(\\tau)=\\frac{\\gamma( au)}{\\gamma(0)}\\)\n\nFigure 6.4: Función de autocorrelación de un AR(1): \\(\\rho(\\tau)= a_1^\\tau\\)\n\nFigure 6.5: Función de autocorrelación de un AR(1): \\(\\rho(\\tau)= a_1^\\tau\\)\n\nFigure 6.6: AR(1) considerando en conjunto \\(X_t = 5 + 0.9 X_{t-1} + U_t\\); \\(X_0 = 50\\) y \\(X_t = \\frac{5}{1 - 0.9} + \\sum_{j = 0}^{t-1} 0.9^j U_{t-j}\\), y que \\(U_t \\sim \\mathcal{N}(0, 4)\\)\nLa Figura 6.1 ilustra el comportamiento que se debería\nobservar en una serie considerando el procedimiento iterativo de\nconstrucción. Por su parte, la Figura 6.2 ilustra el\nproceso o trayectoria de la solución de la serie de tiempo. Finalmente,\nlas Figuras 6.3 y 6.3 muestran el\ncorrelograma calculado considerando una función de autocorrelación\naplicada al porceso real y una función de autocorrelación aplicada al\nproceso teórico, respectivamente.Recordemos que una trayectoria de equilibrio o solución de un \\(AR(1)\\) es\ncomo se muestra en la ecuación (6.6). Así, nuestra serie\nsimulada cumple con la característica de que los errores son más\nrelevantes cuando la serie es corta. Por el contrario, los errores son\nmenos relevantes, cuando la serie es muy larga. La Figura\n6.6 ilustra esta observación de la trayectoria de\nequilibrio.","code":"\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(latex2exp)\n\n# Parametros:\na0 <- 5; a1 <- 0.9; X_0 <- (a0/(1 - a1)); T <- 1000\n# Definimos un data frame para almacenar el proceso, agregamos una columna para el tiempo\nX_t <- data.frame(Tiempo = c(0:T))\n\n#  Parte estocastica de la serie de tiempo:\nset.seed(12345)\n\n# Agregamos un término estocástico al data frame\nX_t$U_t <- rnorm(T+1, mean = 0, sd = 4)\n# Agregamos columnas con NA's para un proceso teorico y uno real\nX_t$X_t <- NA\nX_t$XR_t <- NA\n\n# La serie teórica inicia en un valor inicial X_0\nX_t$X_t[1] <- X_0\n\n# La serie real inicia en un valor inicial X_0\nX_t$XR_t[1] <- X_0\n\n# Agregamos una columna para la función de Autocorrelación teórica:\nX_t$rho <-NA\n\nfor (i in 2:(T + 1)) {\n  # Real:\n  X_t$XR_t[i] = a0 + a1*X_t$XR_t[i-1] + X_t$U_t[i-1]\n  \n  # Teórico:\n  X_t$X_t[i] = X_t$X_t[i-1] + (a1^(i-1))*X_t$U_t[i-1]\n  \n  # Autocorrelación:\n  X_t$rho[i-1] = a1^(i-1)\n}\n\nhead(X_t)\n#>   Tiempo        U_t      X_t     XR_t      rho\n#> 1      0  2.3421153 50.00000 50.00000 0.900000\n#> 2      1  2.8378641 52.10790 52.34212 0.810000\n#> 3      2 -0.4372133 54.40657 54.94577 0.729000\n#> 4      3 -1.8139887 54.08785 54.01398 0.656100\n#> 5      4  2.4235498 52.89769 51.79859 0.590490\n#> 6      5 -7.2718239 54.32877 54.04228 0.531441\n\nggplot(data = X_t, aes(x = Tiempo, y = X_t)) + \n  geom_line(size = 0.5, color = \"#0F531C\") +\n  theme_light() + \n  xlab(\"Tiempo\") + \n  ylab(TeX(\"$X_t$\")) + \n  theme(plot.title = element_text(size = 11, face = \"bold\", hjust = 0)) + \n  theme(plot.subtitle = element_text(size = 10, hjust = 0)) + \n  theme(plot.caption = element_text(size = 10, hjust = 0)) +\n  theme(plot.margin = unit(c(1,1,1,1), \"cm\")) +\n  labs(\n    title = \"Comportamiento del Proceso Teórico\",\n    subtitle = \"Con un error con Distribución Normal (media = 0, desviación estándar = 4)\",\n    caption = \"Fuente: Elaboración propia.\"\n  )\n\nacf(X_t$XR_t, lag.max = 30, col = \"blue\", \n    ylab = \"Autocorrelacion\",\n    xlab=\"Rezagos\", \n    main=\"Funcion de Autocorrelacion Real\")\n\nbarplot(X_t$rho[1:30], names.arg = c(1:30), col = \"blue\", border=\"blue\", density = c(10,20), \n        ylab = \"Autocorrelacion\", \n        xlab=\"Rezagos\", \n        main=\"Funcion de Autocorrelacion Teórica\")\n\nacf(X_t$XR_t, lag.max = 30, col = \"blue\", \n    ylab = \"Autocorrelacion\",\n    xlab=\"Rezagos\", \n    main=\"Funcion de Autocorrelacion Real\")\n\nggplot(data = X_t, aes(x = Tiempo)) +\n  geom_line(aes(y = XR_t), size = 0.5, color = \"darkred\") +\n  geom_line(aes(y = X_t), size = 1, color = \"#0F531C\") +\n  theme_bw() + \n  xlab(\"Tiempo\") + \n  ylab(TeX(\"$X_t$\")) + \n  theme(plot.title = element_text(size = 11, face = \"bold\", hjust = 0)) + \n  theme(plot.subtitle = element_text(size = 10, hjust = 0)) + \n  theme(plot.caption = element_text(size = 10, hjust = 0)) +\n  theme(plot.margin = unit(c(1,1,1,1), \"cm\")) +\n  labs(\n    title = \"Comportamiento de los Procesos Real y Teórico\",\n    subtitle = \"Con un error con Distribución Normal (media = 0, desviación estándar = 4)\",\n    caption = \"Fuente: Elaboración propia.\"\n  )"},{"path":"procesos-estacionarios-univariados.html","id":"ar2","chapter":"6 Procesos estacionarios univariados","heading":"6.1.2 AR(2)","text":"Una vez analizado el caso de \\(AR(1)\\) analizaremos el caso del \\(AR(2)\\).\nLa ecuación generalizada del proceso autoregresivo de orden 2 (denotado\ncomo \\(AR(2)\\)) puede ser escrito como:\\[\\begin{equation}\n    X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + U_t\n    \\tag{6.11}\n\\end{equation}\\]Para el segundo ejemplo consideremos una aplicación una serie de\ntiempo en especifico:","code":""},{"path":"procesos-estacionarios-univariados.html","id":"ejemplo-ar2","chapter":"6 Procesos estacionarios univariados","heading":"6.1.2.1 EJEMPLO AR(2)","text":"Recordando el tema pasado y la serie en la que evaluamos los cambios de\nprecio del ACTIVO AMZN como si fueran retornos:\nFigure 5.5: Serie de tiempo de los precios de apertura de año en los últimos 20 años\nPrimero que nada es importante cargar los datos un objeto series de\ntiempo. Esto nos lo permite la función ts(). Además debemos serciorarnos\nde que los datos esten en orden cronológico.Dado que queremos saber si existe un proceso \\(AR(2)\\) en estos cambio\ndebemos calcularlo. Para ello utilizamos la función \\(lm()\\) que realizará una regresión lineal y veremos la relación de los valores con sus valores pasados en \\(t-2\\):Veamos la tabla de la regresión lineal:\nAR(2) de los precios de apertura de AMZN\nLa tabla anterior claramente indica que hay una relación entre el valor del precio y sus valores anteriores en un proceso AR(2).Así pues es importante modificar la serie de tiempo para ilustrar como se puede controlar los efectos de los autoregresores \\(AR(2)\\). Para ello, utilizaremos la función \\(arima()\\). En “order” tenemos un vector \\(c(p,d,q)\\) que corresponde \\(p\\) el grado de AR, \\(d\\) el grado de diferención y \\(q\\) el grado de MA que utilizaremos. El valor \\(q\\) quedaráá en \\(0\\) por ahora pero será analizado más adelante.Veamos si las raices inversas mantienen la estabilidad al ser menores 1.\nFigure 6.7: Raices AR(2) Inversas de la serie de tiempo\nClaramente se puede en la Figura 6.7 ver que los valores de las raices inversas están dentro del circulo unitario y, por consiguiente son menores 1. Ahora veamos como se ve la estimación ajustada AR(2) con el plot original.\nFigure 6.8: Diferencia entre la serie de tiempo original de precios de AMZN y su AR(2)\nConsecuentemente en la Figura 6.8 es pocible ver la manera en la que se suaviza un poco la línea lo cual debe ayudarnos hacer una mejor estimación.","code":"\n#install.packages(\"pacman\")\n#pacman nos permite cargar varias librerias en una sola línea\nlibrary(pacman)\npacman::p_load(tidyverse,BatchGetSymbols,ggplot2,lubridate,readxl,forecast,stats,stargazer)\n#Primero determinamos el lapso de tiempo\npd<-Sys.Date()-(365*20) #primer fecha\npd\n#> [1] \"2002-10-03\"\nld<-Sys.Date() #última fecha\nld\n#> [1] \"2022-09-28\"\n#Intervalos de tiempo\nint<-\"monthly\"\n\n#Datos a elegir\ndt<-c(\"AMZN\")\n\n#Descargando los valores\ndata1<- BatchGetSymbols(tickers = dt,\n                       first.date = pd,\n                       last.date = ld,\n                       freq.data = int,\n                       do.cache = FALSE,\n                       thresh.bad.data = 0)\n#> Warning: `BatchGetSymbols()` was deprecated in BatchGetSymbols 2.6.4.\n#> Please use `yfR::yf_get()` instead.\n#> 2022-05-01: Package BatchGetSymbols will soon be replaced by yfR. \n#> More details about the change is available at github <<www.github.com/msperlin/yfR>\n#> You can install yfR by executing:\n#> \n#> remotes::install_github('msperlin/yfR')\n\n#Generando data frame con los valores\ndata_precio_amzn<-data1$df.tickers\ncolnames(data_precio_amzn)\n#>  [1] \"ticker\"              \"ref.date\"           \n#>  [3] \"volume\"              \"price.open\"         \n#>  [5] \"price.high\"          \"price.low\"          \n#>  [7] \"price.close\"         \"price.adjusted\"     \n#>  [9] \"ret.adjusted.prices\" \"ret.closing.prices\"\nret_20_amazn<-ggplot(data=data_precio_amzn, aes(x=ref.date))+\n  geom_line(aes(y=price.open))+\n  labs(title=\"Precios de apertura de AMZN en los últimos 20 años\",y=\"Retornos\", x=\"Año\")+\n  theme_light()\nret_20_amazn\ndata_precio_amzn<-data_precio_amzn[order(data_precio_amzn$ref.date),]\nhead(data_precio_amzn)#dado que ya estaba en orden cronológico nuestro df no cambia\n#> # A tibble: 6 × 10\n#>   ticker ref.date     volume price…¹ price…² price…³ price…⁴\n#>   <chr>  <date>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 AMZN   2002-10-03   3.72e9   0.840    1.01   0.818   0.968\n#> 2 AMZN   2002-11-01   4.13e9   0.961    1.23   0.91    1.17 \n#> 3 AMZN   2002-12-02   3.11e9   1.21     1.25   0.922   0.944\n#> 4 AMZN   2003-01-02   3.38e9   0.960    1.16   0.928   1.09 \n#> 5 AMZN   2003-02-03   2.32e9   1.10     1.12   0.980   1.10 \n#> 6 AMZN   2003-03-03   3.28e9   1.11     1.40   1.07    1.30 \n#> # … with 3 more variables: price.adjusted <dbl>,\n#> #   ret.adjusted.prices <dbl>, ret.closing.prices <dbl>,\n#> #   and abbreviated variable names ¹​price.open,\n#> #   ²​price.high, ³​price.low, ⁴​price.close\n#hagamos el objeto ts\nprice_amazn_ts<-ts(data_precio_amzn$price.open)\nplot(price_amazn_ts)#de esta manera podemos ver que se cargo bien debido a que es igual al ggplot\npriceopen<-data_precio_amzn$price.open\npriceopen_amazn<-as.data.frame(priceopen)\npriceopen_amazn$priceopen_lag1<-lag(priceopen_amazn$priceopen,1)\npriceopen_amazn$priceopen_lag2<-lag(priceopen_amazn$priceopen,2)\nar2_amazn<-lm(priceopen~priceopen_lag1+priceopen_lag2, data=priceopen_amazn)\nAR_price_amazn_ts<-Arima(price_amazn_ts,order=c(2,0,0),method = \"ML\")\ncomp_20_amazn<-autoplot(AR_price_amazn_ts, main = \"Raices AR(2)\")+theme_light()\ncomp_20_amazn\nplot(AR_price_amazn_ts$x,col=\"black\", main = \"Diferencia entre la serie de tiempo original y AR(2)\",xlab=\"Tiempo\",ylab=\"Precio\")+lines(fitted(AR_price_amazn_ts),col=\"blue\")#> integer(0)"}]
